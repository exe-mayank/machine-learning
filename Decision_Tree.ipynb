{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a Decision Tree, and how does it work"
      ],
      "metadata": {
        "id": "X22tHoRwWmDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree is a supervised machine learning algorithm used for classification and regression. It resembles a flowchart-like structure where internal nodes represent tests on features, branches represent outcomes of those tests, and leaf nodes represent final predictions or decisions.\n",
        "\n",
        "The process begins at the root node, where the algorithm chooses the best feature to split the dataset. This choice is based on criteria like Gini Impurity, Information Gain, or Variance Reduction—depending on whether it’s a classification or regression problem. The goal is to divide the data into subsets that are as pure as possible (i.e., contain mostly one class or have low variance).\n",
        "\n",
        "Once the best feature is chosen, the dataset is split accordingly, and the process repeats recursively on each subset. This continues until a stopping condition is met—such as reaching a maximum depth, achieving pure nodes, or running out of features to split on.\n",
        "\n",
        "In classification, each leaf node ends with the most common class among the data points in that subset. In regression, it ends with the average of the target values.\n",
        "\n",
        "Decision Trees are easy to interpret and visualize, making them useful for understanding how decisions are made. However, they can overfit the training data, especially when the tree is too deep. Techniques like pruning, setting a maximum depth, or using ensemble methods like Random Forests are often used to improve performance.\n",
        "\n",
        "Overall, Decision Trees provide a powerful and interpretable model, especially when simplicity and transparency are important."
      ],
      "metadata": {
        "id": "VcJaNjqwWqFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  What are impurity measures in Decision Trees"
      ],
      "metadata": {
        "id": "kugACUo6W6fb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impurity measures in Decision Trees are metrics used to evaluate how \"mixed\" or \"impure\" a set of data is at a node. The goal of the tree is to split data in a way that each resulting subset is as pure as possible — meaning most or all data points in a subset belong to the same class.\n",
        "\n",
        "Here are the most common impurity measures:\n",
        "\n",
        "1. Gini Impurity\n",
        "Measures the likelihood of misclassifying a randomly chosen element.\n",
        "\n",
        "Formula:\n",
        "\n",
        "𝐺\n",
        "𝑖\n",
        "𝑛\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "2\n",
        "Gini=1−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "2\n",
        "​\n",
        "\n",
        "where\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the proportion of samples belonging to class\n",
        "𝑖\n",
        "i, and\n",
        "𝐶\n",
        "C is the number of classes.\n",
        "\n",
        "Used in CART (Classification and Regression Trees).\n",
        "\n",
        "2. Entropy (Information Gain)\n",
        "Derived from information theory.\n",
        "\n",
        "Measures the amount of uncertainty or disorder in the data.\n",
        "\n",
        "Formula:\n",
        "\n",
        "𝐸\n",
        "𝑛\n",
        "𝑡\n",
        "𝑟\n",
        "𝑜\n",
        "𝑝\n",
        "𝑦\n",
        "=\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "𝑝\n",
        "𝑖\n",
        ")\n",
        "Entropy=−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (p\n",
        "i\n",
        "​\n",
        " )\n",
        "Information Gain is calculated by subtracting the weighted entropy of child nodes from the entropy of the parent.\n",
        "\n",
        "Common in ID3 and C4.5 algorithms.\n",
        "\n",
        "3. Variance Reduction (for Regression Trees)\n",
        "Measures the reduction in variance after a split.\n",
        "\n",
        "A split that minimizes the variance of the target values in each subset is considered better."
      ],
      "metadata": {
        "id": "RDwVJBYQW82m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the mathematical formula for Gini Impurity"
      ],
      "metadata": {
        "id": "qhOieUQUXEeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mathematical formula for Gini Impurity is:\n",
        "\n",
        "Gini\n",
        "=\n",
        "1\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "2\n",
        "Gini=1−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "2\n",
        "​\n",
        "\n",
        "Where:\n",
        "𝐶\n",
        "C = number of classes\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  = the proportion of samples belonging to class\n",
        "𝑖\n",
        "i at a given node\n",
        "\n",
        "Example:\n",
        "Suppose a node has 3 classes with the following proportions:\n",
        "\n",
        "Class A: 0.5\n",
        "\n",
        "Class B: 0.3\n",
        "\n",
        "Class C: 0.2\n",
        "\n",
        "Then:\n",
        "\n",
        "Gini\n",
        "=\n",
        "1\n",
        "−\n",
        "(\n",
        "0.5\n",
        "2\n",
        "+\n",
        "0.3\n",
        "2\n",
        "+\n",
        "0.2\n",
        "2\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "(\n",
        "0.25\n",
        "+\n",
        "0.09\n",
        "+\n",
        "0.04\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "0.38\n",
        "=\n",
        "0.62\n",
        "Gini=1−(0.5\n",
        "2\n",
        " +0.3\n",
        "2\n",
        " +0.2\n",
        "2\n",
        " )=1−(0.25+0.09+0.04)=1−0.38=0.62\n",
        "Interpretation:\n",
        "Gini = 0 means the node is pure (all samples belong to one class).\n",
        "\n",
        "Higher Gini values indicate more impurity or class mixture.\n",
        "\n",
        "The Decision Tree aims to split data to minimize Gini impurity at each node."
      ],
      "metadata": {
        "id": "ATqcl11vXHtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is the mathematical formula for Entropy"
      ],
      "metadata": {
        "id": "AXPMHHPrXOGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mathematical formula for Entropy in the context of Decision Trees is:\n",
        "\n",
        "Entropy\n",
        "=\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "𝑝\n",
        "𝑖\n",
        ")\n",
        "Entropy=−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (p\n",
        "i\n",
        "​\n",
        " )\n",
        "Where:\n",
        "𝐶\n",
        "C = number of classes\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  = proportion of samples belonging to class\n",
        "𝑖\n",
        "i at a given node\n",
        "\n",
        "The logarithm is base 2 because entropy measures information in bits\n",
        "\n",
        "Example:\n",
        "Suppose a node has two classes:\n",
        "\n",
        "Class A: 0.6\n",
        "\n",
        "Class B: 0.4\n",
        "\n",
        "Then:\n",
        "\n",
        "Entropy\n",
        "=\n",
        "−\n",
        "(\n",
        "0.6\n",
        "log\n",
        "⁡\n",
        "2\n",
        "0.6\n",
        "+\n",
        "0.4\n",
        "log\n",
        "⁡\n",
        "2\n",
        "0.4\n",
        ")\n",
        "≈\n",
        "−\n",
        "(\n",
        "0.6\n",
        "⋅\n",
        "(\n",
        "−\n",
        "0.737\n",
        ")\n",
        "+\n",
        "0.4\n",
        "⋅\n",
        "(\n",
        "−\n",
        "1.322\n",
        ")\n",
        ")\n",
        "≈\n",
        "−\n",
        "(\n",
        "−\n",
        "0.442\n",
        "+\n",
        "−\n",
        "0.529\n",
        ")\n",
        "=\n",
        "0.971\n",
        "Entropy=−(0.6log\n",
        "2\n",
        "​\n",
        " 0.6+0.4log\n",
        "2\n",
        "​\n",
        " 0.4)≈−(0.6⋅(−0.737)+0.4⋅(−1.322))≈−(−0.442+−0.529)=0.971\n",
        "Interpretation:\n",
        "Entropy = 0 means the node is pure (all samples belong to one class).\n",
        "\n",
        "Maximum entropy occurs when all classes are equally likely (e.g., 0.5/0.5 in binary classification), indicating maximum disorder.\n",
        "\n",
        "Decision Trees aim to minimize entropy through splits that increase information gain."
      ],
      "metadata": {
        "id": "J3_20UdOXRBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What is Information Gain, and how is it used in Decision Trees"
      ],
      "metadata": {
        "id": "2_bleSqtXX74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Information Gain is a key concept in building Decision Trees, particularly in algorithms like ID3 and C4.5. It measures the reduction in entropy (or uncertainty) about the target variable after a dataset is split based on a feature. In essence, Information Gain tells us how much “information” a feature provides in classifying the data. The Decision Tree uses this measure to decide which feature to split on at each step, with the goal of creating the purest child nodes.\n",
        "\n",
        "Mathematically, Information Gain is calculated as the difference between the entropy of the parent node and the weighted sum of the entropies of the child nodes. The formula is:\n",
        "\n",
        "Information Gain\n",
        "=\n",
        "Entropy(Parent)\n",
        "−\n",
        "∑\n",
        "𝑘\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "𝑁\n",
        "𝑘\n",
        "𝑁\n",
        "⋅\n",
        "Entropy(Child\n",
        "𝑘\n",
        ")\n",
        "Information Gain=Entropy(Parent)−\n",
        "k=1\n",
        "∑\n",
        "n\n",
        "​\n",
        "  \n",
        "N\n",
        "N\n",
        "k\n",
        "​\n",
        "\n",
        "​\n",
        " ⋅Entropy(Child\n",
        "k\n",
        "​\n",
        " )\n",
        "Here,\n",
        "𝑁\n",
        "N is the total number of samples in the parent node, and\n",
        "𝑁\n",
        "𝑘\n",
        "N\n",
        "k\n",
        "​\n",
        "  is the number in each child node. Entropy is a measure of impurity—higher entropy means more disorder or mixed classes, while lower entropy indicates purer groups.\n",
        "\n",
        "When building the tree, the algorithm calculates the Information Gain for each available feature and selects the one with the highest gain to split the data. This process continues recursively for each branch, creating a tree structure where each node represents a decision point based on the most informative features.\n",
        "\n",
        "By maximizing Information Gain at each step, the Decision Tree efficiently reduces uncertainty, leading to more accurate predictions. This makes Information Gain a fundamental guiding principle in Decision Tree learning."
      ],
      "metadata": {
        "id": "Z78IeoKvXavK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.  What is the difference between Gini Impurity and Entropy"
      ],
      "metadata": {
        "id": "1QkNhM_sXpQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gini Impurity and Entropy are two commonly used impurity measures in Decision Tree algorithms, helping to determine the best feature for splitting the dataset at each node. Although they aim to achieve the same goal—measuring how impure or mixed the data is—they differ slightly in their mathematical formulations and interpretations.\n",
        "\n",
        "Gini Impurity measures the probability of incorrectly classifying a randomly chosen element if it were randomly labeled according to the distribution of class labels in the node. It is calculated using the formula:\n",
        "\n",
        "𝐺\n",
        "𝑖\n",
        "𝑛\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "−\n",
        "∑\n",
        "𝑝\n",
        "𝑖\n",
        "2\n",
        "Gini=1−∑p\n",
        "i\n",
        "2\n",
        "​\n",
        "\n",
        "where\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the probability of an instance belonging to class\n",
        "𝑖\n",
        "i. Gini tends to perform well and is computationally simpler and faster since it doesn’t involve logarithmic calculations.\n",
        "\n",
        "Entropy, on the other hand, is derived from information theory and measures the amount of disorder or uncertainty in the dataset. It is given by the formula:\n",
        "\n",
        "𝐸\n",
        "𝑛\n",
        "𝑡\n",
        "𝑟\n",
        "𝑜\n",
        "𝑝\n",
        "𝑦\n",
        "=\n",
        "−\n",
        "∑\n",
        "𝑝\n",
        "𝑖\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "𝑝\n",
        "𝑖\n",
        ")\n",
        "Entropy=−∑p\n",
        "i\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (p\n",
        "i\n",
        "​\n",
        " )\n",
        "This measure is used to calculate Information Gain, a key component of the ID3 and C4.5 algorithms. Entropy generally provides a more precise evaluation of impurity, especially when class distributions are uneven.\n",
        "\n",
        "In practice, both measures often lead to similar splits and comparable performance, though Gini Impurity is more commonly used in modern implementations like the CART algorithm due to its simplicity. Entropy, however, offers a more theoretically sound approach when dealing with information-based models. The choice between the two often comes down to the specific algorithm being used or preferences related to computation and interpretability."
      ],
      "metadata": {
        "id": "AawBcB_zXrnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What is the mathematical explanation behind Decision Trees"
      ],
      "metadata": {
        "id": "JzXDpi1WX3_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mathematical foundation of Decision Trees lies in recursively partitioning the feature space based on a criterion that maximizes the separation of classes (in classification) or minimizes prediction error (in regression). The goal is to build a tree structure where each internal node corresponds to a decision based on a feature, and each leaf node represents a prediction.\n",
        "\n",
        "🔷 For Classification Trees:\n",
        "Select the Best Split: At each node, the algorithm evaluates all possible splits across all features. For each split:\n",
        "\n",
        "Compute the impurity of the parent node (e.g., Gini or Entropy).\n",
        "\n",
        "Compute the impurity of each child node.\n",
        "\n",
        "Calculate the weighted average impurity of the child nodes.\n",
        "\n",
        "Compute the gain:\n",
        "\n",
        "Gain\n",
        "=\n",
        "Impurity\n",
        "parent\n",
        "−\n",
        "∑\n",
        "𝑘\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "𝑁\n",
        "𝑘\n",
        "𝑁\n",
        "⋅\n",
        "Impurity\n",
        "child\n",
        "𝑘\n",
        "Gain=Impurity\n",
        "parent\n",
        "​\n",
        " −\n",
        "k=1\n",
        "∑\n",
        "n\n",
        "​\n",
        "  \n",
        "N\n",
        "N\n",
        "k\n",
        "​\n",
        "\n",
        "​\n",
        " ⋅Impurity\n",
        "child\n",
        "k\n",
        "​\n",
        "\n",
        "​\n",
        "\n",
        "The split with the highest gain (or lowest weighted impurity) is chosen.\n",
        "\n",
        "Recursive Partitioning:\n",
        "\n",
        "This process repeats for each resulting child node until a stopping condition is met (pure node, max depth, min samples, etc.).\n",
        "\n",
        "🔷 For Regression Trees:\n",
        "The algorithm uses metrics like Mean Squared Error (MSE) or Mean Absolute Error (MAE).\n",
        "\n",
        "For each potential split:\n",
        "\n",
        "MSE\n",
        "=\n",
        "1\n",
        "𝑁\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑁\n",
        "(\n",
        "𝑦\n",
        "𝑖\n",
        "−\n",
        "𝑦\n",
        "^\n",
        ")\n",
        "2\n",
        "MSE=\n",
        "N\n",
        "1\n",
        "​\n",
        "  \n",
        "i=1\n",
        "∑\n",
        "N\n",
        "​\n",
        " (y\n",
        "i\n",
        "​\n",
        " −\n",
        "y\n",
        "^\n",
        "​\n",
        " )\n",
        "2\n",
        "\n",
        "The goal is to minimize the total MSE across child nodes after a split.\n",
        "\n"
      ],
      "metadata": {
        "id": "iQZLsuZnX6sx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is Pre-Pruning in Decision Trees"
      ],
      "metadata": {
        "id": "0p9L1rSeYEmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-pruning in Decision Trees is a technique used to prevent overfitting by stopping the tree from growing too complex or deep. It involves placing restrictions on the tree’s growth during training, ensuring that it does not create overly specific splits that could lead to poor generalization to new data.\n",
        "\n",
        "Pre-pruning is typically achieved by setting certain criteria that limit the tree’s growth, such as:\n",
        "\n",
        "Maximum Depth: This restricts how deep the tree can grow. Limiting the depth prevents the tree from capturing too many fine-grained details, which could lead to overfitting.\n",
        "\n",
        "Minimum Samples per Leaf: This requires that a node must have a minimum number of samples before it can be split. If a node has fewer samples than this threshold, it becomes a leaf, reducing the chances of the tree learning from noise.\n",
        "\n",
        "Minimum Samples per Split: This condition ensures that a node has enough samples to split further. If the number of samples is too small, no further split occurs, helping to avoid creating overly specific branches.\n",
        "\n",
        "Maximum Features: This restricts the number of features to consider when choosing the best split, which can help prevent the model from focusing too heavily on irrelevant features.\n",
        "\n",
        "While pre-pruning reduces the risk of overfitting by limiting the complexity of the tree, it also carries the risk of underfitting. If pruning is too aggressive, the tree might not capture enough of the underlying patterns in the data, leading to poor model performance. Therefore, careful tuning of the pre-pruning parameters is essential for achieving the right balance between bias and variance."
      ],
      "metadata": {
        "id": "jblGklCdYGvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is Post-Pruning in Decision Trees"
      ],
      "metadata": {
        "id": "9K-133PsYRAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Post-pruning in Decision Trees is a technique used to reduce overfitting by simplifying a fully grown tree after it has been trained. Unlike pre-pruning, which limits the tree's growth early, post-pruning allows the tree to develop fully and then removes parts of the tree that do not improve the model's performance on unseen data.\n",
        "\n",
        "The process begins by growing the tree to its maximum depth, capturing as much information from the training data as possible. Once the tree is fully grown, post-pruning evaluates subtrees (branches or leaf nodes) to see if pruning them improves generalization. The idea is to remove branches that capture noise or irrelevant patterns without contributing significantly to predictive power.\n",
        "\n",
        "One common method of post-pruning is cost-complexity pruning (CCP), which balances the tree's complexity and its error. It involves finding a subtree that minimizes the cost function:\n",
        "\n",
        "Cost\n",
        "=\n",
        "Error\n",
        "+\n",
        "𝛼\n",
        "×\n",
        "Tree Size\n",
        "Cost=Error+α×Tree Size\n",
        "where\n",
        "𝛼\n",
        "α controls the trade-off between tree size and error. A larger\n",
        "𝛼\n",
        "α results in more pruning, leading to a simpler tree.\n",
        "\n",
        "Post-pruning helps improve a model's performance on new, unseen data by removing unnecessary complexity. However, it can be computationally expensive since the tree must first be fully grown. There's also a risk of underfitting if too much pruning is applied, causing the tree to become too simplistic. Therefore, balancing pruning is key for optimal model performance."
      ],
      "metadata": {
        "id": "aZevILbsYTgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is the difference between Pre-Pruning and Post-Pruning"
      ],
      "metadata": {
        "id": "TtjPLcV3YcI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-pruning and Post-pruning are two techniques used in Decision Trees to prevent overfitting by controlling the tree's complexity, but they differ in when pruning occurs and how the tree’s growth is managed.\n",
        "\n",
        "Pre-pruning (early stopping) involves setting restrictions during the tree construction process, before the tree reaches its full depth. It stops the tree from growing further based on certain criteria, such as limiting the maximum depth, requiring a minimum number of samples per leaf or split, or limiting the number of leaf nodes. This method aims to prevent the tree from becoming too complex and overfitting the training data. However, pre-pruning can risk underfitting if the tree is stopped too early and misses important patterns in the data.\n",
        "\n",
        "Post-pruning, on the other hand, allows the tree to grow fully and fit the training data as well as possible. After the tree is fully grown, unnecessary branches or subtrees are removed based on their contribution to the tree’s performance. Cost-complexity pruning (CCP) is a common post-pruning method, which balances tree error and complexity by pruning subtrees that don’t significantly improve prediction accuracy. Post-pruning is typically more computationally expensive than pre-pruning because the tree must first be fully built, but it can help reduce overfitting by simplifying an overly complex tree.\n",
        "\n",
        "In summary, pre-pruning controls tree complexity during growth, while post-pruning removes unnecessary parts after the tree is built, with both methods aiming to balance bias and variance in the model."
      ],
      "metadata": {
        "id": "-aw8C35QYeg6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What is a Decision Tree Regressor\n"
      ],
      "metadata": {
        "id": "t8w0lO9qYnid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree Regressor is a type of Decision Tree algorithm specifically designed for regression tasks, where the goal is to predict continuous numerical values rather than categorical labels. It works by splitting the data into subsets based on feature values, and each leaf node of the tree represents a predicted numerical value.\n",
        "\n",
        "How It Works:\n",
        "The process starts by selecting the feature and threshold that best reduce the variance of the target variable. At each internal node, the data is split in such a way that the variance within the resulting child nodes is minimized. The tree continues splitting until a stopping condition is met (e.g., a maximum depth or minimum number of samples per leaf). Once the tree reaches its leaf nodes, the predicted value for each leaf is the mean of the target values of the training data in that node.\n",
        "\n",
        "Key Metrics:\n",
        "The algorithm typically uses Mean Squared Error (MSE) or Mean Absolute Error (MAE) to evaluate the quality of splits. These metrics help determine how well the split reduces the variance in the target variable.\n",
        "\n",
        "Advantages:\n",
        "Interpretability: The structure of the tree is easy to understand and visualize, making it an interpretable model.\n",
        "\n",
        "Non-Linearity: Decision Trees are capable of modeling complex, non-linear relationships between the features and the target variable.\n",
        "\n",
        "Disadvantages:\n",
        "Overfitting: If the tree is too deep, it may fit the noise in the data, leading to poor generalization.\n",
        "\n",
        "Instability: Small changes in the dataset can lead to drastically different tree structures.\n",
        "\n",
        "Overall, Decision Tree Regressors are a powerful, flexible tool for regression tasks but require careful tuning to prevent overfitting."
      ],
      "metadata": {
        "id": "YuyAymDHYt8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What are the advantages and disadvantages of Decision Trees"
      ],
      "metadata": {
        "id": "ENM-L5QmY2Rr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages of Decision Trees:\n",
        "\n",
        "Easy to Understand and Interpret:\n",
        "\n",
        "Decision Trees are highly interpretable, as they provide a clear flowchart-like structure where each decision or split can be followed logically from root to leaf. This makes them suitable for situations where transparency is important.\n",
        "\n",
        "Non-Linear Relationships:\n",
        "\n",
        "Decision Trees can capture complex, non-linear relationships between features and target variables. Unlike linear models, they do not require a linear relationship assumption.\n",
        "\n",
        "No Need for Feature Scaling:\n",
        "\n",
        "Decision Trees do not require normalization or standardization of features. They are not sensitive to the scale of the data, which can be advantageous compared to models like Logistic Regression or SVMs.\n",
        "\n",
        "Handles Both Numerical and Categorical Data:\n",
        "\n",
        "Decision Trees can handle both numerical and categorical data, making them versatile for a wide range of applications.\n",
        "\n",
        "Works Well with Missing Values:\n",
        "\n",
        "Decision Trees can be adapted to handle missing values, making them more robust in real-world scenarios where data may be incomplete.\n",
        "\n",
        "Disadvantages of Decision Trees:\n",
        "\n",
        "Overfitting:\n",
        "\n",
        "One of the biggest drawbacks of Decision Trees is their tendency to overfit the training data, especially when the tree is too deep. A tree that is too complex may model noise in the data, leading to poor generalization on new, unseen data.\n",
        "\n",
        "Instability:\n",
        "\n",
        "Decision Trees can be highly unstable. A small change in the data can result in a completely different tree structure, making them sensitive to variations in the training data.\n",
        "\n",
        "Bias Toward Features with More Levels:\n",
        "\n",
        "Decision Trees may favor features with more levels (categories) when making splits, potentially leading to bias in situations where features have different numbers of categories.\n",
        "\n",
        "Poor Performance with Unstructured Data:\n",
        "\n",
        "Decision Trees may not perform well with unstructured data (like images, text, or time series) unless used in combination with other methods, such as feature engineering.\n",
        "\n",
        "Greedy Algorithm:\n",
        "\n",
        "The process of building a Decision Tree is greedy; it makes the best split at each step without considering future splits. This can lead to suboptimal trees that do not necessarily result in the best global solution.\n",
        "\n"
      ],
      "metadata": {
        "id": "u30EP-p2Y5vr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. How does a Decision Tree handle missing values"
      ],
      "metadata": {
        "id": "ZfSvPKOUZAIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree can handle missing values in various ways, depending on the implementation and the specific algorithm used. The general approach is to make decisions that minimize the impact of missing data while building the tree. Here are the common strategies used to handle missing values in Decision Trees:\n",
        "\n",
        "1. Surrogate Splits:\n",
        "Surrogate splits are alternative splits that the Decision Tree can use when the primary feature value is missing for a given data point. When the algorithm encounters a missing value in the feature selected for splitting, it checks if there are other features that could serve as a good alternative for the split. These are called surrogate splits and are chosen based on how well they match the primary feature’s splits on the training data.\n",
        "\n",
        "For example, if a split was made based on \"Age\" but a data point is missing this value, the tree might look for another feature, such as \"Income\" or \"Education\", to create a surrogate split that best approximates the decision made by \"Age\".\n",
        "\n",
        "2. Assigning the Most Common Value (for Categorical Data):\n",
        "If a missing value occurs for a categorical feature, the Decision Tree may choose to assign the most frequent or most common category from the non-missing values as the default value when splitting.\n",
        "\n",
        "For instance, if a feature \"Color\" is missing for some data points and the most common value is \"Red\", the tree may treat missing \"Color\" as \"Red\" when making decisions.\n",
        "\n",
        "3. Imputation (Filling Missing Values):\n",
        "Imputation is a technique used before building the tree where missing values are replaced with substituted values, often the mean, median, or mode (for numerical or categorical data, respectively) of that feature. After imputation, the Decision Tree algorithm proceeds as usual without needing special handling for missing values.\n",
        "\n",
        "Imputation is common in data preprocessing and can help ensure the model is trained on complete data.\n",
        "\n",
        "4. Use of Indicator Variables:\n",
        "Another technique is to create a new binary feature (indicator variable) to represent whether the original value was missing. This new feature can help the model account for the fact that the value is missing by adding an extra layer of information.\n",
        "\n",
        "For example, for a feature \"Age\", an additional binary variable \"Age_missing\" might be created, where 1 indicates the original value was missing, and 0 indicates it was present. This allows the tree to consider the absence of a value as a meaningful feature in the split process.\n",
        "\n",
        "5. Handling Missing Values During Training (via Splitting):\n",
        "In some cases, Decision Tree algorithms may handle missing values directly during the splitting process. When encountering a missing value in a feature, the algorithm can assign the sample to the branch (left or right) based on the majority decision from the training set for that split.\n",
        "\n",
        "The algorithm may also treat missing values as a separate category during splitting, allowing the tree to make a decision based on the distribution of missing values."
      ],
      "metadata": {
        "id": "Fkqil26CZCqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How does a Decision Tree handle categorical features"
      ],
      "metadata": {
        "id": "FeADAQUjZLFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree handles categorical features by making splits based on the values of those features. Unlike continuous features (where splits are made based on thresholds), categorical features are split by dividing the data into groups corresponding to each distinct category or combination of categories. Here’s how a Decision Tree handles categorical features:\n",
        "\n",
        "1. Handling Single Categorical Features:\n",
        "Splitting by Category: For a single categorical feature, the tree looks for the best split by separating the data into subsets based on the categories of that feature. The tree evaluates how well each possible split (i.e., grouping of categories) reduces the impurity (e.g., Gini impurity or entropy) at that node.\n",
        "\n",
        "For example, if a feature \"Color\" has categories \"Red\", \"Blue\", and \"Green\", the tree might try to split the data into \"Red\" vs. \"Blue or Green\" or \"Red or Blue\" vs. \"Green\", depending on which split results in the most significant reduction in impurity.\n",
        "\n",
        "2. Handling Multi-Class Categorical Features:\n",
        "In the case of multi-class categorical variables, Decision Trees evaluate all possible splits. If a feature has multiple categories (e.g., \"Red\", \"Blue\", \"Green\", \"Yellow\"), the algorithm tests different groupings of these categories to determine which one minimizes the impurity the most.\n",
        "\n",
        "For example, the tree might decide to split the categories into:\n",
        "\n",
        "Group 1: \"Red\" and \"Blue\"\n",
        "\n",
        "Group 2: \"Green\" and \"Yellow\" Or, it might make a different decision based on the distribution of the target variable within those categories.\n",
        "\n",
        "3. One-Hot Encoding:\n",
        "In some implementations, categorical features might be converted into one-hot encoded features before being used in a Decision Tree. One-hot encoding creates new binary features for each category. For example, if \"Color\" has three categories: \"Red\", \"Blue\", and \"Green\", it would be converted into three binary features:\n",
        "\n",
        "Color_Red: 1 if \"Red\", 0 otherwise\n",
        "\n",
        "Color_Blue: 1 if \"Blue\", 0 otherwise\n",
        "\n",
        "Color_Green: 1 if \"Green\", 0 otherwise\n",
        "\n",
        "This allows the tree to treat each category independently and find the best split accordingly.\n",
        "\n",
        "4. Handling High-Cardinality Categorical Features:\n",
        "When a categorical feature has many unique categories (e.g., zip codes or product IDs), the tree can encounter difficulties, such as overfitting or computational inefficiency. In such cases, Decision Trees may resort to grouping similar categories together or applying pruning to reduce the complexity of the tree.\n",
        "\n",
        "5. Binary Categorical Features:\n",
        "If a categorical feature is binary (i.e., it has only two categories, such as \"Yes\" or \"No\"), the Decision Tree treats it similarly to a continuous feature but without the need for thresholding. The tree simply chooses the best way to divide the data into the two categories at each split.\n",
        "\n",
        "6. Pruning and Overfitting:\n",
        "Categorical features with many unique values can lead to overfitting because the Decision Tree may create overly specific splits that do not generalize well to unseen data. Pruning techniques (either pre-pruning or post-pruning) are often employed to prevent this problem and ensure that the tree remains simple and generalizable."
      ],
      "metadata": {
        "id": "KsEfmemvZOD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.  What are some real-world applications of Decision Trees?\n"
      ],
      "metadata": {
        "id": "TZlxFJ2XZWlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Trees are widely used across various industries and real-world applications due to their simplicity, interpretability, and effectiveness in solving both regression and classification problems. Some common real-world applications include:\n",
        "\n",
        "1. Healthcare:\n",
        "Disease Diagnosis: Decision Trees are used to diagnose diseases by analyzing patient symptoms and medical history. For example, they can predict whether a patient has diabetes, heart disease, or cancer based on various health indicators like blood pressure, cholesterol levels, age, and family history.\n",
        "\n",
        "Medical Treatment Decision Support: They help in providing treatment recommendations based on patient conditions. For example, a tree could decide which type of chemotherapy treatment would be most effective based on a patient's specific medical profile.\n",
        "\n",
        "2. Finance and Banking:\n",
        "Credit Scoring: Financial institutions use Decision Trees to predict whether an individual will default on a loan based on features like credit score, income level, employment status, and debt-to-income ratio.\n",
        "\n",
        "Fraud Detection: Banks and payment systems use Decision Trees to detect fraudulent transactions by analyzing transaction patterns, user behavior, and past fraud cases.\n",
        "\n",
        "Risk Assessment: Decision Trees help in determining the risk level of investments and in making decisions regarding loan approval or insurance claims by analyzing various customer-related attributes.\n",
        "\n",
        "3. Retail and E-commerce:\n",
        "Customer Segmentation: Retailers use Decision Trees to segment customers based on purchasing behavior, demographics, and browsing history to target specific marketing campaigns or personalize recommendations.\n",
        "\n",
        "Churn Prediction: Decision Trees can predict which customers are likely to leave a service or stop purchasing from an e-commerce platform, helping businesses take preventive measures to retain customers.\n",
        "\n",
        "4. Marketing and Advertising:\n",
        "Customer Lifetime Value Prediction: Decision Trees can be used to predict the potential value of a customer over time, helping businesses allocate resources effectively and target high-value customers.\n",
        "\n",
        "Campaign Effectiveness: Marketers use Decision Trees to evaluate the effectiveness of advertising campaigns by analyzing customer responses based on various factors such as demographics, product interest, and engagement levels.\n",
        "\n",
        "5. Manufacturing and Quality Control:\n",
        "Predictive Maintenance: Decision Trees are used in manufacturing to predict equipment failures or the need for maintenance based on historical data like machine usage, temperature, and operational conditions, thus reducing downtime and maintenance costs.\n",
        "\n",
        "Quality Control: They help in detecting defects in products by analyzing production parameters, materials used, and environmental factors that may affect product quality.\n",
        "\n",
        "6. Energy and Utilities:\n",
        "Energy Consumption Prediction: Decision Trees can forecast energy consumption patterns based on historical usage data, weather conditions, and other factors, helping utilities optimize energy distribution.\n",
        "\n",
        "Smart Grid Management: They assist in predicting electricity demand in smart grids, enabling utilities to balance supply and demand efficiently.\n",
        "\n",
        "7. Government and Public Sector:\n",
        "Crime Prediction and Prevention: Law enforcement agencies use Decision Trees to predict crime hotspots based on factors such as historical crime data, time of day, location, and demographics, helping in resource allocation and crime prevention.\n",
        "\n",
        "Policy Evaluation: Decision Trees are used to assess the impact of public policies or social programs by analyzing outcomes based on various demographic and economic factors.\n",
        "\n",
        "8. Sports:\n",
        "Player Performance Prediction: Sports teams use Decision Trees to analyze player statistics and predict future performance or injury risks based on historical data, improving team management and strategy.\n",
        "\n",
        "Game Strategy Optimization: Decision Trees help in optimizing strategies during games by predicting the likelihood of various outcomes based on past performance and current game conditions.\n",
        "\n",
        "9. Natural Language Processing (NLP):\n",
        "Text Classification: Decision Trees are used in NLP tasks, such as spam email detection, sentiment analysis, and topic classification. They help categorize text data based on features like word frequency and sentence structure.\n",
        "\n",
        "Named Entity Recognition: Decision Trees can be used to identify and classify named entities in text (such as people, locations, and organizations) by analyzing the context and relationships between words.\n",
        "\n",
        "10. Environmental Monitoring:\n",
        "Pollution Level Prediction: Decision Trees can predict pollution levels based on factors such as weather conditions, traffic patterns, and industrial activity. This helps in managing air quality and taking preventive measures.\n",
        "\n",
        "Disaster Response Planning: They are used to predict and plan responses to natural disasters (e.g., floods, hurricanes) based on environmental factors like rainfall, wind speed, and historical disaster data."
      ],
      "metadata": {
        "id": "qif3WIe_ZZK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical"
      ],
      "metadata": {
        "id": "gBJzw7kkZi3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.  Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy"
      ],
      "metadata": {
        "id": "3heplh1HZlla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__Nyu4rqZpe2",
        "outputId": "710e074d-c6f1-4506-f0a6-e70c304fb32a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the\n",
        "feature importances"
      ],
      "metadata": {
        "id": "GgBcOiIqZ11-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier with Gini Impurity as the criterion\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Get and print the feature importances\n",
        "feature_importances = clf.feature_importances_\n",
        "\n",
        "# Display feature importances for each feature in the Iris dataset\n",
        "print(\"Feature Importances:\")\n",
        "for feature, importance in zip(iris.feature_names, feature_importances):\n",
        "    print(f\"{feature}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrqO6O_KZ3nj",
        "outputId": "b505f798-e738-4d23-d171-39d0cccd03d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances:\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0167\n",
            "petal length (cm): 0.9061\n",
            "petal width (cm): 0.0772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. * Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the\n",
        "model accuracy"
      ],
      "metadata": {
        "id": "HmdffW5IZ_Sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier with Entropy as the criterion\n",
        "clf = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5wVrowDaB2q",
        "outputId": "08af98e8-21ff-4c54-cd25-cd633ecc2fac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean\n",
        "Squared Error (MSE)*"
      ],
      "metadata": {
        "id": "VUa6dJkvaHJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California housing dataset\n",
        "california_housing = fetch_california_housing()\n",
        "X = california_housing.data  # Features\n",
        "y = california_housing.target  # Target labels (house values)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Regressor\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Print the Mean Squared Error\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q44RwHS0aJ1k",
        "outputId": "775b5286-0c6b-498d-df3b-cbf2925c104c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. * Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz*"
      ],
      "metadata": {
        "id": "_FfycHI-a0Jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from graphviz import Source\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Visualize the Decision Tree\n",
        "dot_data = export_graphviz(clf, out_file=None,\n",
        "                           feature_names=iris.feature_names,\n",
        "                           class_names=iris.target_names,\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "\n",
        "# Use Graphviz to render the tree\n",
        "graph = Source(dot_data)\n",
        "graph.render(\"decision_tree\")  # This will save the tree visualization as a file named 'decision_tree.pdf'\n",
        "\n",
        "# Display the tree in the notebook\n",
        "graph.view()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l_wdACcMa2Pf",
        "outputId": "93a8063c-8d95-4790-a2f9-eb97369171d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'decision_tree.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its\n",
        "accuracy with a fully grown tree*"
      ],
      "metadata": {
        "id": "AyJNCQawa8-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Decision Tree Classifier with maximum depth of 3\n",
        "clf_max_depth_3 = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "clf_max_depth_3.fit(X_train, y_train)\n",
        "\n",
        "# Initialize and train a fully grown Decision Tree Classifier (no max depth)\n",
        "clf_full_tree = DecisionTreeClassifier(random_state=42)\n",
        "clf_full_tree.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using both models\n",
        "y_pred_max_depth_3 = clf_max_depth_3.predict(X_test)\n",
        "y_pred_full_tree = clf_full_tree.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of both models\n",
        "accuracy_max_depth_3 = accuracy_score(y_test, y_pred_max_depth_3)\n",
        "accuracy_full_tree = accuracy_score(y_test, y_pred_full_tree)\n",
        "\n",
        "# Print the accuracies\n",
        "print(f\"Accuracy of Decision Tree (max depth 3): {accuracy_max_depth_3 * 100:.2f}%\")\n",
        "print(f\"Accuracy of Fully Grown Decision Tree: {accuracy_full_tree * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEky0LKRbJRj",
        "outputId": "d2a30f1f-eac9-4b58-e53d-b04e6c9398b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Decision Tree (max depth 3): 100.00%\n",
            "Accuracy of Fully Grown Decision Tree: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its\n",
        "accuracy with a default tree*"
      ],
      "metadata": {
        "id": "gDPlUMRZbQxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Decision Tree Classifier with min_samples_split=5\n",
        "clf_min_samples_split_5 = DecisionTreeClassifier(min_samples_split=5, random_state=42)\n",
        "clf_min_samples_split_5.fit(X_train, y_train)\n",
        "\n",
        "# Initialize and train a default Decision Tree Classifier\n",
        "clf_default_tree = DecisionTreeClassifier(random_state=42)\n",
        "clf_default_tree.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using both models\n",
        "y_pred_min_samples_split_5 = clf_min_samples_split_5.predict(X_test)\n",
        "y_pred_default_tree = clf_default_tree.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of both models\n",
        "accuracy_min_samples_split_5 = accuracy_score(y_test, y_pred_min_samples_split_5)\n",
        "accuracy_default_tree = accuracy_score(y_test, y_pred_default_tree)\n",
        "\n",
        "# Print the accuracies\n",
        "print(f\"Accuracy of Decision Tree (min_samples_split=5): {accuracy_min_samples_split_5 * 100:.2f}%\")\n",
        "print(f\"Accuracy of Default Decision Tree: {accuracy_default_tree * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWOtA3-MbXhv",
        "outputId": "22a9a259-a404-409c-d4be-efcd7bfc71db"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Decision Tree (min_samples_split=5): 100.00%\n",
            "Accuracy of Default Decision Tree: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its\n",
        "accuracy with unscaled data*"
      ],
      "metadata": {
        "id": "nLNUy9_Hbama"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the StandardScaler for feature scaling\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply feature scaling to the training and testing data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train a Decision Tree Classifier on the unscaled data\n",
        "clf_unscaled = DecisionTreeClassifier(random_state=42)\n",
        "clf_unscaled.fit(X_train, y_train)\n",
        "\n",
        "# Initialize and train a Decision Tree Classifier on the scaled data\n",
        "clf_scaled = DecisionTreeClassifier(random_state=42)\n",
        "clf_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions using both models\n",
        "y_pred_unscaled = clf_unscaled.predict(X_test)\n",
        "y_pred_scaled = clf_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Calculate the accuracy of both models\n",
        "accuracy_unscaled = accuracy_score(y_test, y_pred_unscaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Print the accuracies\n",
        "print(f\"Accuracy of Decision Tree (Unscaled data): {accuracy_unscaled * 100:.2f}%\")\n",
        "print(f\"Accuracy of Decision Tree (Scaled data): {accuracy_scaled * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO9hSRfPbdZS",
        "outputId": "39066a93-5395-477b-8344-a84c5241fd32"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Decision Tree (Unscaled data): 100.00%\n",
            "Accuracy of Decision Tree (Scaled data): 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass\n",
        "classification*\n"
      ],
      "metadata": {
        "id": "5seufYRVbl4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Wrap the classifier with the OneVsRestClassifier strategy\n",
        "ovr_clf = OneVsRestClassifier(clf)\n",
        "\n",
        "# Train the model on the training data\n",
        "ovr_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = ovr_clf.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Accuracy of One-vs-Rest Decision Tree Classifier: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT_5OR6Ebpfz",
        "outputId": "2455c513-5359-460c-a82d-10a858ad22cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of One-vs-Rest Decision Tree Classifier: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Write a Python program to train a Decision Tree Classifier and display the feature importance scores"
      ],
      "metadata": {
        "id": "0-ix6MKbbyZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Get the feature importance scores\n",
        "feature_importances = clf.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display the feature importance scores\n",
        "feature_names = iris.feature_names\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# Sort the feature importance scores in descending order\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display the feature importance scores\n",
        "print(\"Feature Importance Scores:\")\n",
        "print(importance_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaHJdEVPb1r1",
        "outputId": "39f3c0a3-4b1e-4e81-a565-a3ed07fb2875"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Scores:\n",
            "             Feature  Importance\n",
            "2  petal length (cm)    0.906143\n",
            "3   petal width (cm)    0.077186\n",
            "1   sepal width (cm)    0.016670\n",
            "0  sepal length (cm)    0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance\n",
        "with an unrestricted tree"
      ],
      "metadata": {
        "id": "zqAwxi1rb8fT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (house prices)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Decision Tree Regressor with max_depth=5\n",
        "regressor_max_depth_5 = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
        "regressor_max_depth_5.fit(X_train, y_train)\n",
        "\n",
        "# Initialize and train a fully grown Decision Tree Regressor (no max depth)\n",
        "regressor_full_tree = DecisionTreeRegressor(random_state=42)\n",
        "regressor_full_tree.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using both models\n",
        "y_pred_max_depth_5 = regressor_max_depth_5.predict(X_test)\n",
        "y_pred_full_tree = regressor_full_tree.predict(X_test)\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE) for both models\n",
        "mse_max_depth_5 = mean_squared_error(y_test, y_pred_max_depth_5)\n",
        "mse_full_tree = mean_squared_error(y_test, y_pred_full_tree)\n",
        "\n",
        "# Print the MSE for both models\n",
        "print(f\"Mean Squared Error of Decision Tree (max_depth=5): {mse_max_depth_5:.2f}\")\n",
        "print(f\"Mean Squared Error of Fully Grown Decision Tree: {mse_full_tree:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfynXo_-b7ad",
        "outputId": "270a1a79-e338-4a79-eaca-56f1b662c3c4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error of Decision Tree (max_depth=5): 0.52\n",
            "Mean Squared Error of Fully Grown Decision Tree: 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and\n",
        "visualize its effect on accuracy*"
      ],
      "metadata": {
        "id": "K6pPdrO4cIS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data (without pruning)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate accuracy\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy_no_pruning = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print accuracy of the model without pruning\n",
        "print(f\"Accuracy of Decision Tree without pruning: {accuracy_no_pruning * 100:.2f}%\")\n",
        "\n",
        "# Get the effective alphas (ccp_alpha) for pruning and prune the tree\n",
        "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
        "\n",
        "# Get alphas and corresponding impurities\n",
        "alphas, impurities = path.ccp_alphas, path.impurities\n",
        "\n",
        "# Initialize lists to store accuracies for each value of alpha\n",
        "accuracies = []\n",
        "\n",
        "# Loop over different values of alpha (ccp_alpha) and prune the tree accordingly\n",
        "for alpha in alphas:\n",
        "    # Create a new classifier with the current alpha\n",
        "    clf_pruned = DecisionTreeClassifier(random_state=42, ccp_alpha=alpha)\n",
        "    clf_pruned.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions and calculate accuracy\n",
        "    y_pred_pruned = clf_pruned.predict(X_test)\n",
        "    accuracy_pruned = accuracy_score(y_test, y_pred_pruned)\n",
        "    accuracies.append(accuracy_pruned)\n",
        "\n",
        "# Plot the accuracy vs. alpha (ccp_alpha)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(alphas, accuracies, marker='o', label='Accuracy vs. alpha')\n",
        "plt.xlabel('Alpha (ccp_alpha)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Effect of Cost Complexity Pruning on Accuracy')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Find the optimal alpha for the highest accuracy\n",
        "best_alpha = alphas[accuracies.index(max(accuracies))]\n",
        "print(f\"Optimal alpha (ccp_alpha) for highest accuracy: {best_alpha}\")\n",
        "\n",
        "# Train the pruned model with the optimal alpha\n",
        "clf_pruned_optimal = DecisionTreeClassifier(random_state=42, ccp_alpha=best_alpha)\n",
        "clf_pruned_optimal.fit(X_train, y_train)\n",
        "\n",
        "# Final accuracy with optimal pruning\n",
        "y_pred_pruned_optimal = clf_pruned_optimal.predict(X_test)\n",
        "accuracy_pruned_optimal = accuracy_score(y_test, y_pred_pruned_optimal)\n",
        "\n",
        "# Print the accuracy after pruning\n",
        "print(f\"Accuracy of Decision Tree with optimal pruning: {accuracy_pruned_optimal * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "XYhhq9TscTZe",
        "outputId": "563c8348-89ed-41e3-a7b2-c5a870933c8f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Decision Tree without pruning: 100.00%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal alpha (ccp_alpha) for highest accuracy: 0.0\n",
            "Accuracy of Decision Tree with optimal pruning: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "28. Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision,\n",
        "Recall, and F1-Score*"
      ],
      "metadata": {
        "id": "gfU3UZf7cVVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score for each class\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print Precision, Recall, and F1-Score\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n",
        "\n",
        "# You can also get a classification report that includes Precision, Recall, F1-Score for each class\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoIOrLY4cZKE",
        "outputId": "b5073bea-6f4c-4d2e-8192-4603163c1f3f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-Score: 1.00\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn*"
      ],
      "metadata": {
        "id": "URWUcCU6ceyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix using seaborn heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for Decision Tree Classifier')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Iapbm-ZociEW",
        "outputId": "495d1ffb-96ba-4470-cd99-fde1d112c5a6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAHWCAYAAAB0TPAHAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWNNJREFUeJzt3XdYFFfbBvB7QViQLkhXQESKgthiIXZsUaMSu4mgscQSFTsxKGgUNbFFjTWKGjV2k2jsXewKVuxgC1jADgLC+f7wc19XQEEXB2bvX669rnBm9syzs7s++5w5M6MQQggQERGR7OhIHQAREREVDCZ5IiIimWKSJyIikikmeSIiIplikiciIpIpJnkiIiKZYpInIiKSKSZ5IiIimWKSJyIikikm+U/kypUraNy4MczMzKBQKLBx40aN9h8fHw+FQoHIyEiN9luU1atXD/Xq1dNYf8+ePUOPHj1ga2sLhUKBQYMGaazvwigoKAjOzs75es7evXuhUCiwd+/eAolJWxSG/ahQKBAWFqbWdvz4cdSqVQtGRkZQKBSIiYlBWFgYFAqFNEHSe2lVkr927Rp69+6NMmXKwMDAAKampvDz88OMGTOQmppaoNsODAzE2bNnMX78eCxbtgxVq1Yt0O19SkFBQVAoFDA1Nc1xP165cgUKhQIKhQK//PJLvvv/77//EBYWhpiYGA1E++EmTJiAyMhI9OnTB8uWLcM333xToNtzdnZW7TcdHR2Ym5vD29sbvXr1wtGjRwt020VJZGSkaj+965HfHywFZcOGDWjWrBmsrKygr68Pe3t7tG/fHrt375Y6tHfKyMhAu3btkJycjGnTpmHZsmVwcnKSOix6j2JSB/CpbN68Ge3atYNSqUTXrl1RoUIFpKen4+DBgxg2bBjOnz+P+fPnF8i2U1NTcfjwYYwaNQr9+/cvkG04OTkhNTUVenp6BdL/+xQrVgwpKSn4559/0L59e7Vly5cvh4GBAV68ePFBff/3338IDw+Hs7MzfH198/y87du3f9D2crN7927UqFEDY8aM0Wi/7+Lr64shQ4YAAJ4+fYrY2FisWbMGCxYsQHBwMKZOnVpg216wYAGysrLy9Zw6deogNTUV+vr6BRRVzttctmyZWluPHj3w2WefoVevXqo2Y2PjTxZTToQQ6N69OyIjI1GpUiUMHjwYtra2SEhIwIYNG9CwYUNERUWhVq1aksb5WmpqKooV+1+KuHbtGm7cuIEFCxagR48eqvYff/wRI0eOlCJEygOtSPJxcXHo2LEjnJycsHv3btjZ2amW9evXD1evXsXmzZsLbPv3798HAJibmxfYNhQKBQwMDAqs//dRKpXw8/PDypUrsyX5FStWoHnz5li3bt0niSUlJQXFixfXeKK5d+8evLy8NNbfy5cvkZWV9c44HRwc8PXXX6u1TZo0CZ07d8a0adPg5uaGPn36aCymN33ID0YdHZ1P/jksU6YMypQpo9b23XffoUyZMtn23Zvysv81acqUKYiMjMSgQYMwdepUtSHuUaNGYdmyZWpJVWpvv4/37t0DkP3fsWLFimk07tffX9IQoQW+++47AUBERUXlaf2MjAwxduxYUaZMGaGvry+cnJxESEiIePHihdp6Tk5Oonnz5uLAgQOiWrVqQqlUChcXF7FkyRLVOmPGjBEA1B5OTk5CCCECAwNV//+m18950/bt24Wfn58wMzMTRkZGoly5ciIkJES1PC4uTgAQixcvVnverl27xOeffy6KFy8uzMzMxJdffikuXLiQ4/auXLkiAgMDhZmZmTA1NRVBQUHi+fPn791fgYGBwsjISERGRgqlUikePnyoWnbs2DEBQKxbt04AED///LNqWVJSkhgyZIioUKGCMDIyEiYmJqJp06YiJiZGtc6ePXuy7b83X2fdunVF+fLlxYkTJ0Tt2rWFoaGhGDhwoGpZ3bp1VX117dpVKJXKbK+/cePGwtzcXNy5cyfH15dbDHFxcUIIIe7evSu6d+8urK2thVKpFD4+PiIyMlKtj9fvz88//yymTZsmypQpI3R0dER0dHSu+/X15ysnT58+FSVKlBAODg4iKytL1Z6ZmSmmTZsmvLy8hFKpFNbW1qJXr14iOTk5Wx///vuvqFOnjjA2NhYmJiaiatWqYvny5arlOX0+V65cKSpXrqx6ToUKFcT06dOz7as9e/aoPW/16tWicuXKwsDAQFhaWoouXbqI27dvq63z+nN0+/Zt0apVK2FkZCSsrKzEkCFDxMuXL3PdTzkxMjISgYGBqr/ft/9jY2PFV199JSwsLIRSqRRVqlQRf/31V7Z+Hz58KAYOHCgcHR2Fvr6+cHV1FRMnThSZmZnvjCclJUWUKFFCeHh45Om15LQf9+/fL9q2bStKlSol9PX1haOjoxg0aJBISUlRe25CQoIICgoSDg4OQl9fX9ja2oovv/xS9XkVQojjx4+Lxo0bC0tLS2FgYCCcnZ1Ft27d1PoBIMaMGSOEePXevP35f/3dyunfKyGEWLZsmeo9t7CwEB06dBA3b95UW+dd31/SjMLzs7EA/fPPPyhTpkyeh8F69OiBJUuWoG3bthgyZAiOHj2KiIgIxMbGYsOGDWrrXr16FW3btsW3336LwMBALFq0CEFBQahSpQrKly+PgIAAmJubIzg4GJ06dcIXX3yR72HD8+fPo0WLFvDx8cHYsWOhVCpx9epVREVFvfN5O3fuRLNmzVCmTBmEhYUhNTUVM2fOhJ+fH06dOpXtGGX79u3h4uKCiIgInDp1CgsXLoS1tTUmTZqUpzgDAgLw3XffYf369ejevTuAV1W8h4cHKleunG3969evY+PGjWjXrh1cXFxw9+5dzJs3D3Xr1sWFCxdgb28PT09PjB07FqNHj0avXr1Qu3ZtAFB7L5OSktCsWTN07NgRX3/9NWxsbHKMb8aMGdi9ezcCAwNx+PBh6OrqYt68edi+fTuWLVsGe3v7HJ/n6emJZcuWITg4GI6Ojqrh85IlSyI1NRX16tXD1atX0b9/f7i4uGDNmjUICgrCo0ePMHDgQLW+Fi9ejBcvXqBXr15QKpUoUaJEnvbt24yNjdGmTRv8/vvvuHDhAsqXLw8A6N27NyIjI9GtWzcMGDAAcXFxmDVrFqKjoxEVFaWqziMjI9G9e3eUL18eISEhMDc3R3R0NLZu3YrOnTvnuM0dO3agU6dOaNiwoeozERsbi6ioqGyv802v46lWrRoiIiJw9+5dzJgxA1FRUYiOjlarDDMzM9GkSRNUr14dv/zyC3bu3IkpU6bA1dVVIyMWOe3/8+fPw8/PDw4ODhg5ciSMjIywevVqtG7dGuvWrUObNm0AvKow69atizt37qB3794oXbo0Dh06hJCQECQkJGD69Om5bvfgwYNITk7GoEGDoKur+0Gxr1mzBikpKejTpw8sLS1x7NgxzJw5E7dv38aaNWtU63311Vc4f/48vv/+ezg7O+PevXvYsWMHbt68qfq7cePGKFmyJEaOHAlzc3PEx8dj/fr1uW67d+/ecHBwwIQJEzBgwABUq1Yt1+8ZAIwfPx6hoaFo3749evTogfv372PmzJmoU6dOtvc8r99f+kBS/8ooaI8fPxYARKtWrfK0fkxMjAAgevToodY+dOhQAUDs3r1b1ebk5CQAiP3796va7t27J5RKpRgyZIiq7c0q4k15reSnTZsmAIj79+/nGndOlbyvr6+wtrYWSUlJqrbTp08LHR0d0bVr12zb6969u1qfbdq0EZaWlrlu883XYWRkJIQQom3btqJhw4ZCiFdVpa2trQgPD89xH7x48SJbBRQXFyeUSqUYO3asqu348eM5jlII8aoSACDmzp2b47I3K3khhNi2bZsAIH766Sdx/fp1YWxsLFq3bv3e1yhEzpX19OnTBQDxxx9/qNrS09NFzZo1hbGxsXjy5InqdQEQpqam4t69ex+8vTe9/ly8rjgPHDggAKhV40IIsXXrVrX2R48eCRMTE1G9enWRmpqqtu6bowJvfz4HDhwoTE1N31mJvl2BpqenC2tra1GhQgW1bW3atEkAEKNHj1bbHgC1914IISpVqiSqVKmS6zZzklsln9P+b9iwofD29lYbqcvKyhK1atUSbm5uqrZx48YJIyMjcfnyZbXnjxw5Uujq6marUt80Y8YMAUBs2LAhT/HnVMm/XbELIURERIRQKBTixo0bQohXIw05/Vvzpg0bNggA4vjx4++MAW9U8m/GtGbNGrX13v73Kj4+Xujq6orx48errXf27FlRrFgxtfZ3fX9JM2Q/u/7JkycAABMTkzyt/++//wIABg8erNb+unp7+9i9l5eXqroEXlV37u7uuH79+gfH/LbXv3r/+uuvPE+ESkhIQExMDIKCgtSqRR8fHzRq1Ej1Ot/03Xffqf1du3ZtJCUlqfZhXnTu3Bl79+5FYmIidu/ejcTExFwrQ6VSCR2dVx/BzMxMJCUlwdjYGO7u7jh16lSet6lUKtGtW7c8rdu4cWP07t0bY8eORUBAAAwMDDBv3rw8b+tt//77L2xtbdGpUydVm56eHgYMGIBnz55h3759aut/9dVXKFmy5Adv702vR4SePn0K4FWlZ2ZmhkaNGuHBgweqR5UqVWBsbIw9e/YAeFWRP336FCNHjsx23PVdp0KZm5vj+fPn2LFjR55jPHHiBO7du4e+ffuqbat58+bw8PDIcS5MTp9DTX2f3t7/ycnJ2L17N9q3b4+nT5+q9llSUhKaNGmCK1eu4M6dOwBe7d/atWvDwsJCbf/6+/sjMzMT+/fvz3W7+f13KCeGhoaq/3/+/DkePHiAWrVqQQiB6Oho1Tr6+vrYu3cvHj58mGM/r/892bRpEzIyMj44ntysX78eWVlZaN++vdp+srW1hZubm+pz+Fp+vr+Uf7JP8qampgD+9w/h+9y4cQM6OjooW7asWrutrS3Mzc1x48YNtfbSpUtn68PCwiLXL9iH6NChA/z8/NCjRw/Y2NigY8eOWL169TsT/us43d3dsy3z9PTEgwcP8Pz5c7X2t1+LhYUFAOTrtXzxxRcwMTHBqlWrsHz5clSrVi3bvnwtKytLNXlMqVTCysoKJUuWxJkzZ/D48eM8b9PBwSFfk6d++eUXlChRAjExMfj1119hbW2d5+e+7caNG3Bzc1P9WHnN09NTtfxNLi4uH7yttz179gzA/xLHlStX8PjxY1hbW6NkyZJqj2fPnqkmTl27dg0AUKFChXxtr2/fvihXrhyaNWsGR0dHdO/eHVu3bn3nc971OfTw8Mi2fwwMDLL9CNLk9+nt/X/16lUIIRAaGpptn70+i+L1frty5Qq2bt2abT1/f3+19XKS33+HcnLz5k3Vj3ZjY2OULFkSdevWBQDV90WpVGLSpEnYsmULbGxsUKdOHUyePBmJiYmqfurWrYuvvvoK4eHhsLKyQqtWrbB48WKkpaV9cGxvunLlCoQQcHNzy7avYmNjs+2n/H5/KX9kf0ze1NQU9vb2OHfuXL6el9eLO+R2fE0I8cHbyMzMVPvb0NAQ+/fvx549e7B582Zs3boVq1atQoMGDbB9+/YPPsb3to95La8plUoEBARgyZIluH79eraLabxpwoQJCA0NRffu3TFu3DiUKFECOjo6GDRoUL5O3XqzwsmL6Oho1T80Z8+eVavCC1p+Y32X15/p1z+isrKyYG1tjeXLl+e4/seOIFhbWyMmJgbbtm3Dli1bsGXLFixevBhdu3bFkiVLPqrv1zT1Wc7N2/v/9eds6NChaNKkSY7PeXP/NmrUCMOHD89xvXLlyuW6XQ8PDwCvPm+tW7fOb9jIzMxEo0aNkJycjBEjRsDDwwNGRka4c+cOgoKC1L4vgwYNQsuWLbFx40Zs27YNoaGhiIiIwO7du1GpUiUoFAqsXbsWR44cwT///INt27ahe/fumDJlCo4cOfLRpxpmZWVBoVBgy5YtOb6fb/evye8EZSf7JA8ALVq0wPz583H48GHUrFnznes6OTkhKysLV65cUVVjAHD37l08evRIoxd/sLCwwKNHj7K1v13dAK9OTWrYsCEaNmyIqVOnYsKECRg1ahT27NmjqiTefh0AcOnSpWzLLl68CCsrKxgZGX38i8hB586dsWjRIujo6KBjx465rrd27VrUr18fv//+u1r7o0ePYGVlpfpbk1fTev78Obp16wYvLy/UqlULkydPRps2bVCtWrUP6s/JyQlnzpxBVlaWWjV/8eJF1fKC8OzZM2zYsAGlSpVSfU5dXV2xc+dO+Pn5vfMfTldXVwCvfiTkNsqSG319fbRs2RItW7ZEVlYW+vbti3nz5iE0NDTHvt78HDZo0EBt2aVLlyS/mMrrU+/09PRy/B69ydXVFc+ePXvvejn5/PPPYWFhgZUrV+KHH37I94+Zs2fP4vLly1iyZAm6du2qas/t0ImrqyuGDBmCIUOG4MqVK/D19cWUKVPwxx9/qNapUaMGatSogfHjx2PFihXo0qUL/vzzT7Vz4D+Eq6srhBBwcXF55w8f+jRkP1wPAMOHD4eRkRF69OiBu3fvZlt+7do1zJgxA8Cr4WYA2WbKvr7oSPPmzTUWl6urKx4/fowzZ86o2l5fGONNycnJ2Z77+qIwuQ2x2dnZwdfXF0uWLFH7IXHu3Dls375d9ToLQv369TFu3DjMmjULtra2ua6nq6ubbZRgzZo1qmOgr73+MZLTD6L8GjFiBG7evIklS5Zg6tSpcHZ2RmBg4AcPVX7xxRdITEzEqlWrVG0vX77EzJkzYWxsrBpO1aTU1FR88803SE5OxqhRo1Q/gtq3b4/MzEyMGzcu23Nevnyp2n+NGzeGiYkJIiIisl2g6F2jNklJSWp/6+jowMfHB0Dun8OqVavC2toac+fOVVtny5YtiI2N1ej36UNYW1ujXr16mDdvHhISErItf32NC+DV/j18+DC2bduWbb1Hjx7h5cuXuW6nePHiGDFiBGJjYzFixIgc9/Mff/yBY8eO5fj81z8K3nyeEEL179ZrKSkp2d5TV1dXmJiYqPb/w4cPs23/ff+e5EdAQAB0dXURHh6ebTtCiGyfIypYWlHJu7q6YsWKFejQoQM8PT3Vrnh36NAh1SlPAFCxYkUEBgZi/vz5ePToEerWrYtjx45hyZIlaN26NerXr6+xuDp27IgRI0agTZs2GDBgAFJSUjBnzhyUK1dObeLZ2LFjsX//fjRv3hxOTk64d+8efvvtNzg6OuLzzz/Ptf+ff/4ZzZo1Q82aNfHtt9+qTqEzMzN75zD6x9LR0cGPP/743vVatGiBsWPHolu3bqhVqxbOnj2L5cuXZ7uwiaurK8zNzTF37lyYmJjAyMgI1atXz/fx7d27d+O3337DmDFjVKf0LV68GPXq1UNoaCgmT56cr/4AoFevXpg3bx6CgoJw8uRJODs7Y+3atYiKisL06dM/aqIVANy5c0dVfT179gwXLlzAmjVrkJiYiCFDhqB3796qdevWrYvevXsjIiICMTExaNy4MfT09HDlyhWsWbMGM2bMQNu2bWFqaopp06ahR48eqFatGjp37gwLCwucPn0aKSkpuQ699+jRA8nJyWjQoAEcHR1x48YNzJw5E76+vmqjXm/S09PDpEmT0K1bN9StWxedOnVSnULn7OyM4ODgj9o/mjB79mx8/vnn8Pb2Rs+ePVGmTBncvXsXhw8fxu3bt3H69GkAwLBhw/D333+jRYsWqtNknz9/jrNnz2Lt2rWIj49XG4F62+sra06ZMgV79uxB27ZtYWtri8TERGzcuBHHjh3DoUOHcnyuh4cHXF1dMXToUNy5cwempqZYt25dtrkKly9fRsOGDdG+fXt4eXmhWLFi2LBhA+7evasaVVuyZAl+++03tGnTBq6urnj69CkWLFgAU1NTjfz4d3V1xU8//YSQkBDEx8ejdevWMDExQVxcHDZs2IBevXph6NChH70dyiMppvRL5fLly6Jnz57C2dlZ6OvrCxMTE+Hn5ydmzpypdvpMRkaGCA8PFy4uLkJPT0+UKlXqnRfDedvbp27ldgqdEK8uclOhQgWhr68v3N3dxR9//JHtlJRdu3aJVq1aCXt7e6Gvry/s7e1Fp06d1E7lye1iODt37hR+fn7C0NBQmJqaipYtW+Z6MZy3T9FbvHix2kVfcvPmKXS5ye0UuiFDhgg7OzthaGgo/Pz8xOHDh3M89e2vv/4SXl5eolixYjleDCcnb/bz5MkT4eTkJCpXriwyMjLU1gsODhY6Ojri8OHD73wNub3fd+/eFd26dRNWVlZCX19feHt7Z3sf3vUZeNf28P8XHlEoFMLU1FSUL19e9OzZUxw9ejTX582fP19UqVJFGBoaChMTE+Ht7S2GDx8u/vvvP7X1/v77b1GrVi3VZ+Ozzz4TK1euVC1/+xS6tWvXisaNGwtra2uhr68vSpcuLXr37i0SEhJU6+R2MZxVq1aJSpUqCaVSKUqUKPHOi+G8LbeLrbzLuy6Gk5Nr166Jrl27CltbW6GnpyccHBxEixYtxNq1a9XWe/r0qQgJCRFly5YV+vr6wsrKStSqVUv88ssvIj09PU+xvd6PJUqUEMWKFRN2dnaiQ4cOYu/evap1ctqPFy5cEP7+/sLY2FhYWVmJnj17itOnT6t9Hx48eCD69esnPDw8hJGRkTAzMxPVq1cXq1evVvVz6tQp0alTJ1G6dGnVBZNatGghTpw4oRYnPvAUutfWrVsnPv/8c2FkZCSMjIyEh4eH6Nevn7h06ZJqnXd9f0kzFELkY1YVERERFRlacUyeiIhIGzHJExERyRSTPBERkUwxyRMREckUkzwREZFMMckTERHJFJM8ERGRTMnyineGzaZJHQJ9Qg//kf6qaURUMAwKOEsZVuqvsb5So2dprC9NkWWSJyIiyhOFvAe05f3qiIiItBgreSIi0l4avJV1YcQkT0RE2ovD9URERFQUsZInIiLtxeF6IiIimeJwPRERERVFrOSJiEh7cbieiIhIpjhcT0REREURK3kiItJeHK4nIiKSKQ7XExERUVHESp6IiLQXh+uJiIhkisP1REREVBSxkiciIu3F4XoiIiKZ4nA9ERERFUWs5ImISHvJvJJnkiciIu2lI+9j8vL+CUNERKTFWMkTEZH24nA9ERGRTMn8FDp5/4QhIiLSYqzkiYhIe3G4noiISKY4XE9ERERFESt5IiLSXjIfrpf3qyMiInoXhUJzj3zYv38/WrZsCXt7eygUCmzcuFFtuRACo0ePhp2dHQwNDeHv748rV67k++UxyRMREX1iz58/R8WKFTF79uwcl0+ePBm//vor5s6di6NHj8LIyAhNmjTBixcv8rUdDtcTEZH2kmi4vlmzZmjWrFmOy4QQmD59On788Ue0atUKALB06VLY2Nhg48aN6NixY563w0qeiIi0lwaH69PS0vDkyRO1R1paWr5DiouLQ2JiIvz9/VVtZmZmqF69Og4fPpyvvpjkiYiINCAiIgJmZmZqj4iIiHz3k5iYCACwsbFRa7exsVEtyysO1xMRkfbS4HB9SEgIBg8erNamVCo11v+HYJInIiLtpcGL4SiVSo0kdVtbWwDA3bt3YWdnp2q/e/cufH1989UXh+uJiIgKERcXF9ja2mLXrl2qtidPnuDo0aOoWbNmvvpiJU9ERNpLotn1z549w9WrV1V/x8XFISYmBiVKlEDp0qUxaNAg/PTTT3Bzc4OLiwtCQ0Nhb2+P1q1b52s7TPJERKS9JEryJ06cQP369VV/vz6WHxgYiMjISAwfPhzPnz9Hr1698OjRI3z++efYunUrDAwM8rUdhRBCaDTyQsCw2TSpQ6BP6OE/wVKHQEQFxKCAS1HDlr9prK/Uf/pqrC9NYSVPRETaS+Z3oWOSJyIi7SXzG9QUqiT/4sULpKenq7WZmppKFA0REVHRJvlPmJSUFPTv3x/W1tYwMjKChYWF2oOIiKjASHQXuk9F8iQ/bNgw7N69G3PmzIFSqcTChQsRHh4Oe3t7LF26VOrwiIhIzhQ6mnsUQpIP1//zzz9YunQp6tWrh27duqF27dooW7YsnJycsHz5cnTp0kXqEImIiIokyX96JCcno0yZMgBeHX9PTk4GAHz++efYv3+/lKEREZHccbi+YJUpUwZxcXEAAA8PD6xevRrAqwrf3NxcwsiIiEjuFAqFxh6FkeRJvlu3bjh9+jQAYOTIkZg9ezYMDAwQHByMYcOGSRwdERFR0SX5Mfng4P9drczf3x8XL17EyZMnUbZsWfj4+EgYGRERyV1hrcA1RfIk/zYnJyeYmZlxqJ6IiAqevHO89MP1kyZNwqpVq1R/t2/fHpaWlnBwcFAN4xMREVH+SZ7k586di1KlSgEAduzYgR07dmDLli1o1qwZj8kTEVGBkvvEO8mH6xMTE1VJftOmTWjfvj0aN24MZ2dnVK9eXeLoiIhIzgprctYUySt5CwsL3Lp1CwCwdetW+Pv7AwCEEMjMzJQyNCIioiJN8ko+ICAAnTt3hpubG5KSktCsWTMAQHR0NMqWLStxdEREJGes5AvYtGnT0L9/f3h5eWHHjh0wNjYGACQkJKBv374SR1f4+FVwwNqwVrj+R0+kbglGy5qu2dYJ/aYmri/vheSN32PzhK/gam/+6QOlAvXniuVo1qgBqlXyRpeO7XD2zBmpQ6ICxPe74Mj9mLzkSV5PTw9Dhw7FjBkzUKlSJVV7cHAwevToIWFkhZORgR7OXr+PQb/tznH5kHZV0fdLXwyYuRN1Bq3E8xcZ+OenACj1dD9xpFRQtm75F79MjkDvvv3w55oNcHf3QJ/e3yIpKUnq0KgA8P2mjyF5kgeAa9eu4fvvv4e/vz/8/f0xYMAAXL9+XeqwCqXtJ+IRvvQQ/j50Lcfl/VpXxqQ/j2HTkes4F/8APX7ZCjtLI3xZK3vFT0XTsiWLEdC2PVq3+QquZcvixzHhMDAwwMb166QOjQoA3+8CptDgoxCSPMlv27YNXl5eOHbsGHx8fODj44OjR4+qhu8p75xtzWBXwgi7o2+q2p6kpOP4pURU97CXMDLSlIz0dMReOI8aNWup2nR0dFCjRi2cOR0tYWRUEPh+Fzy5D9dLPvFu5MiRCA4OxsSJE7O1jxgxAo0aNZIosqLH1qI4AODewxS19nsPU2Dz/8uoaHv46CEyMzNhaWmp1m5paYm4OI5+yQ3fb/pYkif52NhY1Z3n3tS9e3dMnz79vc9PS0tDWlqaWpvIegmFjuQvjYiICrnCWoFriuTD9SVLlkRMTEy29piYGFhbW7/3+RERETAzM1N7vLy2swAiLfwS/7+Ct36rare2KI67b1X3VDRZmFtAV1c326SrpKQkWFlZSRQVFRS+3wVP7sP1kif5nj17olevXpg0aRIOHDiAAwcOYOLEiejduzd69uz53ueHhITg8ePHao9irv6fIPLCJz7xMRKSn6O+bylVm0lxfVRzt8XRi/9JGBlpip6+Pjy9yuPokcOqtqysLBw9ehg+FSu945lUFPH9po8l+Zh2aGgoTExMMGXKFISEhAAA7O3tERYWhgEDBrz3+UqlEkqlUq1NzkP1RgZ6aue9O9uYwqdMSTx8+gK37j/F7I2nMKJjdVy98wjxdx9jzDe1kJD0PNfZ+FT0fBPYDaE/jED58hVQwdsHfyxbgtTUVLRuEyB1aFQA+H4XrMJagWuK5NlQoVAgODgYwcHBePr0KQDAxMRE4qgKr8puNtg+uZ3q78m96wEAlu04j15Tt2PKmhMobqCHWQP8YW6sxKHz/+HL0PVIy+AlguWiabMv8DA5Gb/N+hUPHtyHu4cnfpu3EJYcvpUlvt8FTN45HgohhJAygAYNGmD9+vXZ7h//5MkTtG7dGrt353zRl3cxbDZNQ9FRUfDwn2CpQyCiAmJQwKWoZeBKjfWVtKSTxvrSFMkr+b179yI9PT1b+4sXL3DgwAEJIiIiIm3B4foCcuaNay9fuHABiYmJqr8zMzOxdetWODg4SBEaERFpCSb5AuLr66s67aBBgwbZlhsaGmLmzJkSREZERCQPkiX5uLg4CCFQpkwZHDt2DCVLllQt09fXh7W1NXR1eVMVIiIqOKzkC4iTkxOAV+d8EhERSULeOV76i+EAwLJly+Dn5wd7e3vcuHEDwKv7zP/1118SR0ZERFR0SZ7k58yZg8GDB+OLL77Ao0ePkJn56nxuCwuLPF27noiI6EPxsrYFbObMmViwYAFGjRqldgy+atWqOHv2rISRERGR3DHJF7C4uDhUqpT9GsxKpRLPnz+XICIiIiJ5kDzJu7i45HgXuq1bt8LT0/PTB0RERFpD7pW85Fe8Gzx4MPr164cXL15ACIFjx45h5cqViIiIwMKFC6UOj4iIZKywJmdNkTzJ9+jRA4aGhvjxxx+RkpKCzp07w8HBATNmzEDHjh2lDo+IiKjIkjzJp6amok2bNujSpQtSUlJw7tw5REVFwdHRUerQiIhI7uRdyEt/TL5Vq1ZYunQpACA9PR1ffvklpk6ditatW2POnDkSR0dERHIm92Pykif5U6dOoXbt2gCAtWvXwsbGBjdu3MDSpUvx66+/ShwdERFR0SX5cH1KSgpMTEwAANu3b0dAQAB0dHRQo0YN1dXviIiICkJhrcA1RfJKvmzZsti4cSNu3bqFbdu2oXHjxgCAe/fuwdTUVOLoiIhIzjhcX8BGjx6NoUOHwtnZGdWrV0fNmjUBvKrqc7pIDhEREeWN5MP1bdu2xeeff46EhARUrFhR1d6wYUO0adNGwsiIiEj2CmcBrjGSJ3kAsLW1ha2trVrbZ599JlE0RESkLQrrMLumSD5cT0RERAWjUFTyREREUpB7Jc8kT0REWkvuSZ7D9URERDLFSp6IiLSW3Ct5JnkiItJe8s7xHK4nIiKSK1byRESktThcT0REJFNyT/IcriciIpIpVvJERKS1ZF7IM8kTEZH24nA9ERERaVRmZiZCQ0Ph4uICQ0NDuLq6Yty4cRBCaHQ7rOSJiEhrSVXIT5o0CXPmzMGSJUtQvnx5nDhxAt26dYOZmRkGDBigse0wyRMRkdaSarj+0KFDaNWqFZo3bw4AcHZ2xsqVK3Hs2DGNbofD9URERBqQlpaGJ0+eqD3S0tJyXLdWrVrYtWsXLl++DAA4ffo0Dh48iGbNmmk0JiZ5IiLSWgqF5h4REREwMzNTe0REROS43ZEjR6Jjx47w8PCAnp4eKlWqhEGDBqFLly4afX0criciIq2lo6O54fqQkBAMHjxYrU2pVOa47urVq7F8+XKsWLEC5cuXR0xMDAYNGgR7e3sEBgZqLCYmeSIiIg1QKpW5JvW3DRs2TFXNA4C3tzdu3LiBiIgIJnkiIiJNkGp2fUpKCnR01I+Y6+rqIisrS6PbYZInIiL6xFq2bInx48ejdOnSKF++PKKjozF16lR0795do9thkiciIq0l1Sl0M2fORGhoKPr27Yt79+7B3t4evXv3xujRozW6HSZ5IiLSWlIN15uYmGD69OmYPn16gW6Hp9ARERHJFCt5IiLSWnK/QQ2TPBERaS25J3kO1xMREckUK3kiItJaMi/kmeSJiEh7cbieiIiIiiRW8kREpLVkXsgzyRMRkfbicD0REREVSazkiYhIa8m8kGeSJyIi7cXheiIiIiqSWMkTEZHWknkhzyRPRETai8P1REREVCTJspJ/+E+w1CHQJ+TY40+pQ6BP6PbCjlKHQDIi80JenkmeiIgoLzhcT0REREUSK3kiItJaMi/kmeSJiEh7cbieiIiIiiRW8kREpLVkXsgzyRMRkfbicD0REREVSazkiYhIa8m9kmeSJyIirSXzHM/heiIiIrliJU9ERFqLw/VEREQyJfMcz+F6IiIiuWIlT0REWovD9URERDIl8xzP4XoiIiK5YiVPRERaS0fmpTyTPBERaS2Z53gO1xMREckVK3kiItJanF1PREQkUzryzvEcriciIpIrVvJERKS1OFxPREQkUzLP8RyuJyIikitW8kREpLUUkHcpzyRPRERai7PriYiIqEhiJU9ERFqLs+uJiIhkSuY5nsP1REREciVpks/IyEDDhg1x5coVKcMgIiItpaNQaOxRGEk6XK+np4czZ85IGQIREWmxQpqbNUby4fqvv/4av//+u9RhEBERyY7kE+9evnyJRYsWYefOnahSpQqMjIzUlk+dOlWiyIiISO44u76AnTt3DpUrVwYAXL58WW2Z3Hc+ERFJS+5pRvIkv2fPHqlDICIikiXJk/ybbt++DQBwdHSUOBIiItIGhXVWvKZIPvEuKysLY8eOhZmZGZycnODk5ARzc3OMGzcOWVlZUodHREQyptDgozCSvJIfNWoUfv/9d0ycOBF+fn4AgIMHDyIsLAwvXrzA+PHjJY6QiIioaJI8yS9ZsgQLFy7El19+qWrz8fGBg4MD+vbtyyRPREQFRu4TvCUfrk9OToaHh0e2dg8PDyQnJ0sQERERaQsdheYe+XXnzh18/fXXsLS0hKGhIby9vXHixAnNvj6N9vYBKlasiFmzZmVrnzVrFipWrChBRERERAXr4cOH8PPzg56eHrZs2YILFy5gypQpsLCw0Oh2JB+unzx5Mpo3b46dO3eiZs2aAIDDhw/j1q1b+PfffyWOjoiI5Eyq4fpJkyahVKlSWLx4sarNxcVF49vJU5L/+++/89zhm8fW86Ju3bq4fPkyZs+ejYsXLwIAAgIC0LdvX9jb2+erLyIiovzQZI5PS0tDWlqaWptSqYRSqcy27t9//40mTZqgXbt22Ldvn2oeWs+ePTUXEACFEEK8byUdnbyN6isUCmRmZn50UB/rxUupI6BPybHHn1KHQJ/Q7YUdpQ6BPiGDAh5v/mb5aY315XplA8LDw9XaxowZg7CwsGzrGhgYAAAGDx6Mdu3a4fjx4xg4cCDmzp2LwMBAjcWUpySvafm585yPj0+++2eS1y5M8tqFSV67FHSS77pCc3dCXfCVe54reX19fVStWhWHDh1StQ0YMADHjx/H4cOHNRaTJMfkfX19oVAo8L7fF4VlZICIiOTpQ2bF5ya3hJ4TOzs7eHl5qbV5enpi3bp1mgsIH5jknz9/jn379uHmzZtIT09XWzZgwID3Pj8uLu5DNktERCQLfn5+uHTpklrb5cuX4eTkpNHt5DvJR0dH44svvkBKSgqeP3+OEiVK4MGDByhevDisra3zlOQ1/SKIiIg+hFSz64ODg1GrVi1MmDAB7du3x7FjxzB//nzMnz9fo9vJ93nywcHBaNmyJR4+fAhDQ0McOXIEN27cQJUqVfDLL798UBDXrl3D999/D39/f/j7+2PAgAG4du3aB/VFRESUV1Jdu75atWrYsGEDVq5ciQoVKmDcuHGYPn06unTpooFX9T/5TvIxMTEYMmQIdHR0oKuri7S0NJQqVQqTJ0/GDz/8kO8Atm3bBi8vLxw7dgw+Pj7w8fHB0aNHUb58eezYsSPf/RERERUFLVq0wNmzZ/HixQvExsZq/PQ54AOG6/X09FSn1FlbW+PmzZvw9PSEmZkZbt26le8ARo4cieDgYEycODFb+4gRI9CoUaN890lERJQXcr/VbL6TfKVKlXD8+HG4ubmhbt26GD16NB48eIBly5ahQoUK+Q4gNjYWq1evztbevXt3TJ8+Pd/9ERER5ZXMc3z+h+snTJgAOzs7AMD48eNhYWGBPn364P79+x80YaBkyZKIiYnJ1h4TEwNra+t890dERESv5LuSr1q1qur/ra2tsXXr1o8KoGfPnujVqxeuX7+OWrVqAQCioqIwadIkDB48+KP6JiIiehe532pW8hvUhIaGwsTEBFOmTEFISAgAwN7eHmFhYXk6HY+IiOhDyTzH5z/Ju7i4vPOXz/Xr1/PVn0KhQHBwMIKDg/H06VMAgImJSX7D0np/rliOJYt/x4MH91HO3QMjfwiF9wdcEpgKP2ODYhgZ4I3mlR1hZarE2RuPMGrFKUTHJUsdGhUQfr/pQ+U7yQ8aNEjt74yMDERHR2Pr1q0YNmxYvgOIi4vDy5cv4ebmppbcr1y5Aj09PTg7O+e7T22zdcu/+GVyBH4cEw5v74pYvmwJ+vT+Fn9t2gpLS0upwyMNm97tM3g4mqHv/CNIfJSKdrWcsW5YPdT6YQsSH6VKHR5pGL/fBYuz698ycODAHNtnz56NEydO5DuAoKAgdO/eHW5ubmrtR48excKFC7F3795896ltli1ZjIC27dG6zVcAgB/HhGP//r3YuH4dvu3ZS+LoSJMM9HTRoqojvvn1AA5fvg8AmLzxHJr42qNbg7KIWH9W4ghJ0/j9Llgyz/H5n12fm2bNmn3QhfWjo6Ph5+eXrb1GjRo5zrondRnp6Yi9cB41atZSteno6KBGjVo4czpawsioIBTTVaCYrg5epGeptaemZ6JGuZISRUUFhd9v+lgam3i3du1alChRIt/PUygUqmPxb3r8+HGe7kCXlpaW7dZ+QjfvdwIq6h4+eojMzMxsw3aWlpaIi8vf/Agq/J69eIljVx5gaKvyuJLwGPcep+GrGqVRrawl4u4+kzo80jB+vwseZ9e/pVKlSmo7RQiBxMRE3L9/H7/99lu+A6hTpw4iIiKwcuVK6OrqAgAyMzMRERGBzz///L3Pj4iIQHh4uFrbqNAx+HF0WL5jISoK+s4/gl+//QznprfGy8wsnLnxEOuP3ERFZwupQyMqcjQ2nF1I5TvJt2rVSi3J6+jooGTJkqhXrx48PDzyHcCkSZNQp04duLu7o3bt2gCAAwcO4MmTJ9i9e/d7nx8SEpLtfHqhqx1VPABYmFtAV1cXSUlJau1JSUmwsrKSKCoqSPH3n+HLibtRXF8XJoZ6uPv4BRb2qYUb959LHRppGL/f9LHyneTDwsI0GoCXlxfOnDmDWbNm4fTp0zA0NETXrl3Rv3//PA3/K5XZh+ZfvNRoiIWanr4+PL3K4+iRw2jQ0B8AkJWVhaNHD6Njp68ljo4KUkp6JlLSM2FWXA/1vW0Rvuq01CGRhvH7XfA4XP8WXV1dJCQkZLvkbFJSEqytrfN0HP1t9vb2mDBhQr6fR698E9gNoT+MQPnyFVDB2wd/LFuC1NRUtG4TIHVoVADqV7CFQgFcTXgKFxtjhHXwxZWEJ1hxkMdo5Yjf74KlI+8cn/8kL4TIsT0tLQ36+vp56uPMmTOoUKECdHR0cObMmXeu68MLPrxX02Zf4GFyMn6b9SsePLgPdw9P/DZvISw5nCdLpoZ6+LFdRdhbGOLR83T8c+IWxq87i5eZOX83qWjj95s+hkLklrXf8uuvvwIAgoODMW7cOBgbG6uWZWZmYv/+/YiPj0d09PtP69DR0UFiYiKsra2ho6MDhUKR448HhULxQSMD2jRcT4Bjjz+lDoE+odsLO0odAn1CBgV88fXBf1/UWF9Tv8z/vLSClufdN23aNACvKvm5c+eqZsIDgL6+PpydnTF37tw89RUXF4eSJUuq/p+IiEgKPCb//14n4/r162P9+vWwsPjw03WcnJxy/H8iIiLSnHyfIrhnz56PSvBvW7JkCTZv3qz6e/jw4TA3N0etWrVw48YNjW2HiIjobToKzT0Ko3wn+a+++gqTJk3K1j558mS0a9cu3wFMmDABhoaGAIDDhw9j1qxZmDx5MqysrBAcHJzv/oiIiPJKodDcozDKd5Lfv38/vvjii2ztzZo1w/79+/MdwK1bt1C2bFkAwMaNG9G2bVv06tULEREROHDgQL77IyIiolfyneSfPXuW46lyenp6ePLkSb4DMDY2Vl3Nafv27WjUqBEAwMDAAKmpvG0mEREVHB2FQmOPwijfSd7b2xurVq3K1v7nn3/Cy8sr3wE0atQIPXr0QI8ePXD58mXVKMH58+d5L3kiIipQOhp8FEb5PgMxNDQUAQEBuHbtGho0aAAA2LVrF1asWIG1a9fmO4DZs2cjNDQUN2/exLp161R3Wzp58iQ6deqU7/6IiIjolXwn+ZYtW2Ljxo2YMGEC1q5dC0NDQ1SsWBG7d+/O961mX758iV9//RUjRoyAo6Oj2rK37yxHRESkaYV0lF1jPmiEoXnz5oiKisLz589x/fp1tG/fHkOHDkXFihXz1U+xYsUwefJkvHzJS9QREdGnx2Pyudi/fz8CAwNhb2+PKVOmoEGDBjhy5Ei++2nYsCH27dv3oWEQERFRLvI1XJ+YmIjIyEj8/vvvePLkCdq3b4+0tDRs3LjxgybdAa9OvRs5ciTOnj2LKlWqwMjISG35l19++UH9EhERvU8hLcA1Js9JvmXLlti/fz+aN2+O6dOno2nTptDV1c3z9epz07dvXwDA1KlTsy370BvUEBER5UVhvVKdpuQ5yW/ZsgUDBgxAnz594ObmprEAsrKyNNYXERER/U+ej8kfPHgQT58+RZUqVVC9enXMmjULDx480GgwL1680Gh/RERE78KJd/+vRo0aWLBgARISEtC7d2/8+eefsLe3R1ZWFnbs2IGnT59+UACZmZkYN24cHBwcYGxsjOvXrwN4dT7+77///kF9EhER5QWvXf8WIyMjdO/eHQcPHsTZs2cxZMgQTJw4EdbW1h80SW78+PGIjIzE5MmT1S6XW6FCBSxcuDDf/REREdErH3UlPnd3d0yePBm3b9/GypUrP6iPpUuXYv78+ejSpQt0dXVV7RUrVsTFixc/JjwiIqJ3kvutZvN9xbuc6OrqonXr1mjdunW+n3vnzh3VXejelJWVhYyMDA1ER0RElDMFCml21hDJr6nv5eWV4y1l165di0qVKkkQERERkTxopJL/GKNHj0ZgYCDu3LmDrKwsrF+/HpcuXcLSpUuxadMmqcMjIiIZK6zD7JoieSXfqlUr/PPPP9i5cyeMjIwwevRoxMbG4p9//lHdW56IiKgg8Jh8AevRowe+/vpr7NixQ+pQiIiIZEXySv7+/fto2rQpSpUqheHDh+P06dNSh0RERFpCoVBo7FEYSZ7k//rrLyQkJCA0NBTHjh1D5cqVUb58eUyYMAHx8fFSh0dERDIm9+F6yZM8AFhYWKBXr17Yu3cvbty4gaCgICxbtizHU+uIiIgobyQ/Jv+mjIwMnDhxAkePHkV8fDxsbGykDomIiGSskI6ya0yhqOT37NmDnj17wsbGBkFBQTA1NcWmTZtw+/ZtqUMjIiIZk/sNaiSv5B0cHJCcnIymTZti/vz5aNmyJZRKpdRhERERFXmSJ/mwsDC0a9cO5ubmUodCRERaprBOmNMUyZN8z549pQ6BiIi0VCEdZdeYQnFMnoiIiDRP8kqeiIhIKjoyvwsdkzwREWktDtcTERFRkcRKnoiItBZn1xMREclUYb2IjaZwuJ6IiEimWMkTEZHWknkhzyRPRETai8P1REREVCSxkiciIq0l80KeSZ6IiLSX3Iez5f76iIiICrWJEydCoVBg0KBBGu+blTwREWkthcTj9cePH8e8efPg4+NTIP2zkiciIq2l0OAjv549e4YuXbpgwYIFsLCw+MhXkjMmeSIiIg1IS0vDkydP1B5paWm5rt+vXz80b94c/v7+BRYTkzwREWktHYVCY4+IiAiYmZmpPSIiInLc7p9//olTp07lulxTeEyeiIi0liaPyIeEhGDw4MFqbUqlMtt6t27dwsCBA7Fjxw4YGBhoMILsmOSJiIg0QKlU5pjU33by5Encu3cPlStXVrVlZmZi//79mDVrFtLS0qCrq6uRmJjkiYhIa0kxub5hw4Y4e/asWlu3bt3g4eGBESNGaCzBA0zyRESkxaQ4hc7ExAQVKlRQazMyMoKlpWW29o/FiXdEREQyxUqeiIi0VmGpdPfu3Vsg/TLJExGR1pL6incFrbD8iCEiIiINYyVPRERaS951PJM8ERFpMbkP1zPJU5F3e2FHqUOgT8iiWn+pQ6BPKDV6ltQhFGlM8kREpLXkPjGNSZ6IiLSW3Ifr5f4jhoiISGuxkiciIq0l7zqeSZ6IiLSYzEfrOVxPREQkV6zkiYhIa+nIfMCeSZ6IiLQWh+uJiIioSGIlT0REWkvB4XoiIiJ54nA9ERERFUms5ImISGtxdj0REZFMcbieiIiIiiRW8kREpLXkXskzyRMRkdaS+yl0HK4nIiKSKVbyRESktXTkXcgzyRMRkfbicD0REREVSazkiYhIa3F2PRERkUxxuJ6IiIiKJFbyRESktTi7noiISKY4XE9ERERFEit5IiLSWpxdT0REJFMyz/EcriciIpIrVvJERKS1dGQ+Xs8kT0REWkveKZ7D9URERLLFSp6IiLSXzEt5JnkiItJavBgOERERFUms5ImISGvJfHI9kzwREWkvmed46ZN8ZmYmpk2bhtWrV+PmzZtIT09XW56cnCxRZEREREWb5Mfkw8PDMXXqVHTo0AGPHz/G4MGDERAQAB0dHYSFhUkdHhERyZlCg49CSPIkv3z5cixYsABDhgxBsWLF0KlTJyxcuBCjR4/GkSNHpA6PiIhkTKHB/wojyZN8YmIivL29AQDGxsZ4/PgxAKBFixbYvHmzlKEREREVaZIneUdHRyQkJAAAXF1dsX37dgDA8ePHoVQqpQyNiIhkTqHQ3KMwkjzJt2nTBrt27QIAfP/99wgNDYWbmxu6du2K7t27SxwdERFR0SX57PqJEyeq/r9Dhw5wcnLCoUOH4ObmhpYtW0oYGRERyV0hLcA1RvIk/7YaNWqgRo0aUodBRETaQOZZXvLh+oiICCxatChb+6JFizBp0iQJIiIiIpIHyZP8vHnz4OHhka29fPnymDt3rgQRERGRtpD7KXSSD9cnJibCzs4uW3vJkiVVs+6JiIgKQmGdFa8pklfypUqVQlRUVLb2qKgo2NvbSxARERGRPEheyffs2RODBg1CRkYGGjRoAADYtWsXhg8fjiFDhkgcHRERyZnMC3npk/ywYcOQlJSEvn37qm5OY2BggBEjRiAkJETi6IiISNZknuUVQgghdRAA8OzZM8TGxsLQ0BBubm4fdbW7Fy81GBgRFSoW1fpLHQJ9QqnRswq0/9O3nmqsr4qlTDTWl6ZIXsm/ZmxsjGrVqkkdBhERaZHCOiteUyRJ8gEBAYiMjISpqSkCAgLeue769es/UVRERKRtpJpdHxERgfXr1+PixYswNDRErVq1MGnSJLi7u2t0O5IkeTMzMyj+f8+amZlJEQIREZFk9u3bh379+qFatWp4+fIlfvjhBzRu3BgXLlyAkZGRxrZTaI7JaxKPyRPJF4/Ja5eCPiZ/7vYzjfVVwdH4g597//59WFtbY9++fahTp47GYio0x+SJiIg+OQ0O16elpSEtLU2tTalU5mki+ePHjwEAJUqU0FxAKAQXw7l79y6++eYb2Nvbo1ixYtDV1VV7UN78uWI5mjVqgGqVvNGlYzucPXNG6pCoAPH9lie/yq5YO703rm8fj9ToWWhZz0dteasGFfHPb/1we88kpEbPgk85B4kipZxERETAzMxM7REREfHe52VlZWHQoEHw8/NDhQoVNBqT5JV8UFAQbt68idDQUNjZ2amO1VPebd3yL36ZHIEfx4TD27sili9bgj69v8Vfm7bC0tJS6vBIw/h+y5eRoRJnL9/B0r8OY9XUXtmWFzfUx6GYa1i34xTmjO4iQYTyo8nZ9SEhIRg8eLBaW16q+H79+uHcuXM4ePCgxmJ5TfIkf/DgQRw4cAC+vr5Sh1JkLVuyGAFt26N1m68AAD+OCcf+/Xuxcf06fNsz+z8UVLTx/Zav7VEXsD3qQq7LV24+DgAobafZIV1tpsm6Mq9D82/q378/Nm3ahP3798PR0VFzwfw/yYfrS5UqBRnO/ftkMtLTEXvhPGrUrKVq09HRQY0atXDmdLSEkVFB4PtNJA9CCPTv3x8bNmzA7t274eLiUiDbkTzJT58+HSNHjkR8fLzUoRRJDx89RGZmZrZhWktLSzx48ECiqKig8P0m0iyFBh/50a9fP/zxxx9YsWIFTExMkJiYiMTERKSmpmrgVf2P5MP1HTp0QEpKClxdXVG8eHHo6empLU9OTn7n83OazSh08z9kQkREWkiiaWBz5swBANSrV0+tffHixQgKCtLYdiRP8tOnT/+o50dERCA8PFytbVToGPw4Ouyj+i0qLMwtoKuri6SkJLX2pKQkWFlZSRQVFRS+30Ty8KkOU0ue5AMDAz/q+TnNZhS62lPF6+nrw9OrPI4eOYwGDf0BvDod4+jRw+jY6WuJoyNN4/tNpFm8dn0BePLkCUxNTVX//y6v18tNTrMZte2Kd98EdkPoDyNQvnwFVPD2wR/LliA1NRWt27z7vgBUNPH9li8jQ324liqp+tvZwRI+5Rzw8EkKbiU+hIVpcZSytYCd9avLgZdztgEA3E16grtJmrubmjaR+1nbkiR5CwsLJCQkwNraGubm5jmeGy+EgEKhQGZmpgQRFi1Nm32Bh8nJ+G3Wr3jw4D7cPTzx27yFsOTwrSzx/Zavyl5O2L5woOrvyUNfnSa57O8j6DXmDzSv640FY79RLV82qTsA4Ke5/2L8vH8/bbBUJEhy7fp9+/bBz88PxYoVw759+965bt26dfPdv7ZV8kTahNeu1y4Ffe36y4kpGuurnG1xjfWlKZJU8m8m7g9J4kRERBrB4fqCdSaXa24rFAoYGBigdOnSPB2OiIjoA0ie5H19fd95vXo9PT106NAB8+bNg4GBwSeMjIiI5E7us+slv+Ldhg0b4Obmhvnz5yMmJgYxMTGYP38+3N3dsWLFCvz+++/YvXs3fvzxR6lDJSIimVEoNPcojCSv5MePH48ZM2agSZMmqjZvb284OjoiNDQUx44dg5GREYYMGYJffvlFwkiJiIiKFsmT/NmzZ+Hk5JSt3cnJCWfPngXwakg/ISHhU4dGREQyV0gLcI2RfLjew8MDEydORHp6uqotIyMDEydOhIeHBwDgzp07sLGxkSpEIiKSK6nuUPOJSF7Jz549G19++SUcHR3h4+MD4FV1n5mZiU2bNgEArl+/jr59+0oZJhERUZEjycVw3vb06VMsX74cly9fBgC4u7ujc+fOMDEx+aD+eDEcIvnixXC0S0FfDOf6/Rca66tMycJ3BpiklXxGRgY8PDywadMmfPfdd1KGQkREWqiwzorXFEmPyevp6eHFC839iiIiIqL/kXziXb9+/TBp0iS8fMkxdiIi+rRkPu9O+ol3x48fx65du7B9+3Z4e3vDyMhIbfn69eslioyIiGSvsGZnDZE8yZubm+Orr76SOgwiIiLZkTzJL168WOoQiIhIS8n92vWSJ3kiIiKpyH12vSRJvnLlyti1axcsLCxQqVKld96F7tSpU58wMiIiIvmQJMm3atVKdY/41q1bSxECERGRzAfrJUryY8aMUf3/rVu30KVLF9SvX1+KUIiISIvJfbhe8vPk79+/j2bNmqFUqVIYPnw4Tp8+LXVIREREsiB5kv/rr7+QkJCgund85cqVUb58eUyYMAHx8fFSh0dERLIm78vhFIob1Lzp9u3bWLlyJRYtWoQrV6580JXweIMaIvniDWq0S0HfoObOo/T3r5RHDub6GutLUySv5N+UkZGBEydO4OjRo4iPj+c95ImIiD5CoUjye/bsQc+ePWFjY4OgoCCYmppi06ZNuH37ttShERGRjMl7sL4QXAzHwcEBycnJaNq0KebPn4+WLVuqTq8jIiIqSHKfXS95kg8LC0O7du1gbm4udShERESyInmS79mzp9QhEBGRluK164mIiORK3jm+cEy8IyIiIs1jJU9ERFpL5oU8kzwREWkvuc+u53A9ERGRTLGSJyIircXZ9URERHIl7xzP4XoiIiK5YiVPRERaS+aFPJM8ERFpL86uJyIioiKJlTwREWktzq4nIiKSKQ7XExERUZHEJE9ERCRTHK4nIiKtxeF6IiIiKpJYyRMRkdbi7HoiIiKZ4nA9ERERFUms5ImISGvJvJBnkiciIi0m8yzP4XoiIiKZYiVPRERai7PriYiIZIqz64mIiKhIYiVPRERaS+aFPJM8ERFpMZlneQ7XExERSWD27NlwdnaGgYEBqlevjmPHjml8G0zyRESktRQa/C8/Vq1ahcGDB2PMmDE4deoUKlasiCZNmuDevXsafX1M8kREpLUUCs098mPq1Kno2bMnunXrBi8vL8ydOxfFixfHokWLNPr6mOSJiIg0IC0tDU+ePFF7pKWlZVsvPT0dJ0+ehL+/v6pNR0cH/v7+OHz4sEZjkuXEOwNZvqp3S0tLQ0REBEJCQqBUKqUOhwqYNr/fqdGzpA7hk9Pm97ugaTJfhP0UgfDwcLW2MWPGICwsTK3twYMHyMzMhI2NjVq7jY0NLl68qLmAACiEEEKjPZIknjx5AjMzMzx+/BimpqZSh0MFjO+3duH7XTSkpaVlq9yVSmW2H2b//fcfHBwccOjQIdSsWVPVPnz4cOzbtw9Hjx7VWExaWPMSERFpXk4JPSdWVlbQ1dXF3bt31drv3r0LW1tbjcbEY/JERESfkL6+PqpUqYJdu3ap2rKysrBr1y61yl4TWMkTERF9YoMHD0ZgYCCqVq2Kzz77DNOnT8fz58/RrVs3jW6HSV4mlEolxowZw0k5WoLvt3bh+y0/HTp0wP379zF69GgkJibC19cXW7duzTYZ72Nx4h0REZFM8Zg8ERGRTDHJExERyRSTPBERkUwxyRMVEfHx8VAoFIiJiSmU/dH/hIWFwdfX96P72bt3LxQKBR49epTn5wQFBaF169YfvW2SB068K2Li4+Ph4uKC6OhojfwjQkVHZmYm7t+/DysrKxQr9vEnxvCzVHCePXuGtLQ0WFpaflQ/6enpSE5Oho2NDRR5vAPK48ePIYSAubn5R22b5IGn0BEVEhkZGdDT08t1ua6ursavhvWx0tPToa+vL3UYhY6xsTGMjY1zXZ7X/aavr5/v99zMzCxf65O8cbheImvXroW3tzcMDQ1haWkJf39/PH/+HACwcOFCeHp6wsDAAB4eHvjtt99Uz3NxcQEAVKpUCQqFAvXq1QPw6mpJY8eOhaOjI5RKpeqcy9fS09PRv39/2NnZwcDAAE5OToiIiFAtnzp1Kry9vWFkZIRSpUqhb9++ePbs2SfYE0XT/PnzYW9vj6ysLLX2Vq1aoXv37gCAv/76C5UrV4aBgQHKlCmD8PBwvHz5UrWuQqHAnDlz8OWXX8LIyAjjx4/Hw4cP0aVLF5QsWRKGhoZwc3PD4sWLAeQ8vH7+/Hm0aNECpqamMDExQe3atXHt2jUA7/9M5GTfvn347LPPoFQqYWdnh5EjR6rFXK9ePfTv3x+DBg2ClZUVmjRp8lH7sah63/v/9nD96yH08ePHw97eHu7u7gCAQ4cOwdfXFwYGBqhatSo2btyo9h6/PVwfGRkJc3NzbNu2DZ6enjA2NkbTpk2RkJCQbVuvZWVlYfLkyShbtiyUSiVKly6N8ePHq5aPGDEC5cqVQ/HixVGmTBmEhoYiIyNDszuMpCPok/vvv/9EsWLFxNSpU0VcXJw4c+aMmD17tnj69Kn4448/hJ2dnVi3bp24fv26WLdunShRooSIjIwUQghx7NgxAUDs3LlTJCQkiKSkJCGEEFOnThWmpqZi5cqV4uLFi2L48OFCT09PXL58WQghxM8//yxKlSol9u/fL+Lj48WBAwfEihUrVDFNmzZN7N69W8TFxYldu3YJd3d30adPn0+/c4qI5ORkoa+vL3bu3KlqS0pKUrXt379fmJqaisjISHHt2jWxfft24ezsLMLCwlTrAxDW1tZi0aJF4tq1a+LGjRuiX79+wtfXVxw/flzExcWJHTt2iL///lsIIURcXJwAIKKjo4UQQty+fVuUKFFCBAQEiOPHj4tLly6JRYsWiYsXLwoh3v+ZyKm/4sWLi759+4rY2FixYcMGYWVlJcaMGaOKuW7dusLY2FgMGzZMXLx4UbUtbfO+93/MmDGiYsWKqmWBgYHC2NhYfPPNN+LcuXPi3Llz4vHjx6JEiRLi66+/FufPnxf//vuvKFeunNp7smfPHgFAPHz4UAghxOLFi4Wenp7w9/cXx48fFydPnhSenp6ic+fOattq1aqV6u/hw4cLCwsLERkZKa5evSoOHDggFixYoFo+btw4ERUVJeLi4sTff/8tbGxsxKRJkwpkv9GnxyQvgZMnTwoAIj4+PtsyV1dXteQrxKsvYc2aNYUQ2f9hfs3e3l6MHz9era1atWqib9++Qgghvv/+e9GgQQORlZWVpxjXrFkjLC0t8/qStFKrVq1E9+7dVX/PmzdP2Nvbi8zMTNGwYUMxYcIEtfWXLVsm7OzsVH8DEIMGDVJbp2XLlqJbt245bu/t9z4kJES4uLiI9PT0HNd/32fi7f5++OEH4e7urvYZmT17tjA2NhaZmZlCiFdJvlKlSrntEq3yrvc/pyRvY2Mj0tLSVG1z5swRlpaWIjU1VdW2YMGC9yZ5AOLq1auq58yePVvY2Niobet1kn/y5IlQKpVqSf19fv75Z1GlSpU8r0+FG4frJVCxYkU0bNgQ3t7eaNeuHRYsWICHDx/i+fPnuHbtGr799lvVMT1jY2P89NNPqiHYnDx58gT//fcf/Pz81Nr9/PwQGxsL4NUQXkxMDNzd3TFgwABs375dbd2dO3eiYcOGcHBwgImJCb755hskJSUhJSVF8ztAJrp06YJ169apbi25fPlydOzYETo6Ojh9+jTGjh2r9j727NkTCQkJavu0atWqan326dMHf/75J3x9fTF8+HAcOnQo1+3HxMSgdu3aOR7Hz8tn4m2xsbGoWbOm2gQvPz8/PHv2DLdv31a1ValS5R17RXu86/3Pibe3t9px+EuXLsHHxwcGBgaqts8+++y92y1evDhcXV1Vf9vZ2eHevXs5rhsbG4u0tDQ0bNgw1/5WrVoFPz8/2NrawtjYGD/++CNu3rz53jioaGCSl4Curi527NiBLVu2wMvLCzNnzoS7uzvOnTsHAFiwYAFiYmJUj3PnzuHIkSMftc3KlSsjLi4O48aNQ2pqKtq3b4+2bdsCeHWst0WLFvDx8cG6detw8uRJzJ49G8CrY/mUs5YtW0IIgc2bN+PWrVs4cOAAunTpAuDV7Orw8HC19/Hs2bO4cuWK2j/qRkZGan02a9YMN27cQHBwMP777z80bNgQQ4cOzXH7hoaGBffi3uHtmLXVu97/nGhqv739o06hUEDkcpLU+z4jhw8fRpcuXfDFF19g06ZNiI6OxqhRo/i9lxEmeYkoFAr4+fkhPDwc0dHR0NfXR1RUFOzt7XH9+nWULVtW7fF6wt3rSiAzM1PVl6mpKezt7REVFaW2jaioKHh5eamt16FDByxYsACrVq3CunXrkJycjJMnTyIrKwtTpkxBjRo1UK5cOfz333+fYC8UbQYGBggICMDy5cuxcuVKuLu7o3LlygBe/ai6dOlStvexbNmyuVZ6r5UsWRKBgYH4448/MH36dMyfPz/H9Xx8fHDgwIEcJ0nl9TPxJk9PTxw+fFgtYURFRcHExASOjo7vjFkbvev9zwt3d3ecPXtWNRIAAMePH9dojG5ubjA0NFS7pembDh06BCcnJ4waNQpVq1aFm5sbbty4odEYSFo8hU4CR48exa5du9C4cWNYW1vj6NGjuH//Pjw9PREeHo4BAwbAzMwMTZs2RVpaGk6cOIGHDx9i8ODBsLa2hqGhIbZu3QpHR0cYGBjAzMwMw4YNw5gxY+Dq6gpfX18sXrwYMTExWL58OYBXs+ft7OxQqVIl6OjoYM2aNbC1tYW5uTnKli2LjIwMzJw5Ey1btkRUVBTmzp0r8V4qGrp06YIWLVrg/Pnz+Prrr1Xto0ePRosWLVC6dGm0bdtWNYR/7tw5/PTTT7n2N3r0aFSpUgXly5dHWloaNm3aBE9PzxzX7d+/P2bOnImOHTsiJCQEZmZmOHLkCD777DO4u7u/9zPxtr59+2L69On4/vvv0b9/f1y6dAljxozB4MGD3/vDRFvl9v7nRefOnTFq1Cj06tULI0eOxM2bN/HLL78AQJ7PiX8fAwMDjBgxAsOHD4e+vj78/Pxw//59nD9/Ht9++y3c3Nxw8+ZN/Pnnn6hWrRo2b96MDRs2aGTbVEhIOyVAO124cEE0adJElCxZUiiVSlGuXDkxc+ZM1fLly5cLX19foa+vLywsLESdOnXE+vXrVcsXLFggSpUqJXR0dETdunWFEEJkZmaKsLAw4eDgIPT09ETFihXFli1bVM+ZP3++8PX1FUZGRsLU1FQ0bNhQnDp1SrV86tSpws7OThgaGoomTZqIpUuXqk34oZxlZmYKOzs7AUBcu3ZNbdnWrVtFrVq1hKGhoTA1NRWfffaZmD9/vmo5ALFhwwa154wbN054enoKQ0NDUaJECdGqVStx/fp1IUTOky5Pnz4tGjduLIoXLy5MTExE7dq1VXG87zORU3979+4V1apVE/r6+sLW1laMGDFCZGRkqJbXrVtXDBw48CP3mnzk9v7nNPHuzRnvr0VFRQkfHx+hr68vqlSpIlasWCEAqM5ayGninZmZmVofGzZsEG/+U/72tjIzM8VPP/0knJychJ6enihdurTapNBhw4YJS0tLYWxsLDp06CCmTZuWbRtUdPGKd0REhcTy5cvRrVs3PH78WLI5FyQvHK4nIpLI0qVLUaZMGTg4OOD06dMYMWIE2rdvzwRPGsMkT0QkkcTERIwePRqJiYmws7NDu3bt1K5GR/SxOFxPREQkU5wyS0REJFNM8kRERDLFJE9ERCRTTPJEREQyxSRPREQkU0zyREVAUFAQWrdurfq7Xr16GDRo0CePY+/evVAoFHj06NEn3zYR5R+TPNFHCAoKgkKhgEKhgL6+PsqWLYuxY8fi5cuXBbrd9evXY9y4cXlal4mZSHvxYjhEH6lp06ZYvHgx0tLS8O+//6Jfv37Q09NDSEiI2nrp6elq9xP/GCVKlNBIP0Qkb6zkiT6SUqmEra0tnJyc0KdPH/j7++Pvv/9WDbGPHz8e9vb2cHd3BwDcunUL7du3h7m5OUqUKIFWrVohPj5e1V9mZiYGDx4Mc3NzWFpaYvjw4dnuF/72cH1aWhpGjBiBUqVKQalUomzZsvj9998RHx+P+vXrAwAsLCygUCgQFBQEAMjKykJERARcXFxgaGiIihUrYu3atWrb+ffff1GuXDkYGhqifv36anESUeHHJE+kYYaGhkhPTwcA7Nq1C5cuXcKOHTuwadMmZGRkoEmTJjAxMcGBAwcQFRUFY2NjNG3aVPWcKVOmIDIyEosWLcLBgweRnJz83tt/du3aFStXrsSvv/6K2NhYzJs3D8bGxihVqhTWrVsHALh06RISEhIwY8YMAEBERASWLl2KuXPn4vz58wgODsbXX3+Nffv2AXj1YyQgIAAtW7ZETEwMevTogZEjRxbUbiOigiDpPfCIirg3b+uZlZUlduzYIZRKpRg6dKgIDAwUNjY2Ii0tTbX+smXLhLu7u8jKylK1paWlCUNDQ7Ft2zYhhBB2dnZi8uTJquUZGRnC0dFR7fahb97y9dKlSwKA2LFjR44xvn27UiGEePHihShevLg4dOiQ2rrffvut6NSpkxBCiJCQEOHl5aW2fMSIEbwFMVERwmPyRB9p06ZNMDY2RkZGBrKystC5c2eEhYWhX79+8Pb2VjsOf/r0aVy9ehUmJiZqfbx48QLXrl3D48ePkZCQgOrVq6uWFStWDFWrVs02ZP9aTEwMdHV1Ubdu3TzHfPXqVaSkpKBRo0Zq7enp6ahUqRIAIDY2Vi0OAKhZs2aet0FE0mOSJ/pI9evXx5w5c6Cvrw97e3sUK/a/r5WRkZHaus+ePUOVKlWwfPnybP2ULFnyg7b/IbclffbsGQBg8+bNcHBwUFumVCo/KA4iKnyY5Ik+kpGREcqWLZundStXroxVq1bB2toapqamOa5jZ2eHo0ePok6dOgCAly9f4uTJk6hcuXKO63t7eyMrKwv79u2Dv79/tuWvRxIyMzNVbV5eXlAqlbh582auIwCenp74+++/1dqOHDny/hdJRIUGJ94RfUJdunSBlZUVWrVqhQMHDiAuLg579+7FgAEDcPv2bQDAwIEDMXHiRGzcuBEXL15E375933mOu7OzMwIDA9G9e3ds3LhR1efq1asBAE5OTlAoFNi0aRPu37+PZ8+ewcTEBEOHDkVwcDCWLFmCa9eu4dSpU5g5cyaWLFkCAPjuu+9w5coVDBs2DJcuXcKKFSsQGRlZ0LuIiDSISZ7oEypevDj279+P0qVLIyAgAJ6envj222/x4sULVWU/ZMgQfPPNNwgMDETNmjVhYmKCNm3avLPfOXPmoG3btujbty88PDzQs2dPPH/+HADg4OCA8PBwjBw5EjY2Nujfvz8AYNy4cQgNDUVERAQ8PT3RtGlTbN68GS4uLgCA0qVLY926ddi4cSMqVqyIuXPnYsKECQW4d4hI0xQit9k8REREVKSxkiciIpIpJnkiIiKZYpInIiKSKSZ5IiIimWKSJyIikikmeSIiIplikiciIpIpJnkiIiKZYpInIiKSKSZ5IiIimWKSJyIikqn/AyjqBrlekRlBAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values\n",
        "for max_depth and min_samples_split."
      ],
      "metadata": {
        "id": "EiPf8D9Scomz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Define the parameter grid for max_depth and min_samples_split\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 10, None],  # Different values of max_depth\n",
        "    'min_samples_split': [2, 5, 10]  # Different values of min_samples_split\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV to search for the best hyperparameters\n",
        "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Perform the grid search on the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters found by GridSearchCV\n",
        "print(\"Best hyperparameters found by GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Get the best model from GridSearchCV\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions with the best model on the test data\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy of the model\n",
        "print(f\"Accuracy of the model with optimal hyperparameters: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3Pxgo2ScrDL",
        "outputId": "2315407a-0702-4a9c-b68d-18f1093d71e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters found by GridSearchCV:\n",
            "{'max_depth': 10, 'min_samples_split': 2}\n",
            "Accuracy of the model with optimal hyperparameters: 100.00%\n"
          ]
        }
      ]
    }
  ]
}